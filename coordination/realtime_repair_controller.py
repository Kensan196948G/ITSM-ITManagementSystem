#!/usr/bin/env python3
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¿®å¾©ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼
- GitHub Actionsç›£è¦–ã€ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã€è‡ªå‹•ä¿®å¾©ã®çµ±åˆåˆ¶å¾¡
- ã‚¨ãƒ©ãƒ¼0ä»¶é”æˆã¾ã§ç¶™ç¶šå®Ÿè¡Œã™ã‚‹åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ  
- ä¿®å¾©å±¥æ­´ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡ã«ã‚ˆã‚‹ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆåˆ¶å¾¡
"""

import asyncio
import json
import logging
import signal
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any
import traceback

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from github_actions_monitor import GitHubActionsMonitor
from error_pattern_analyzer import ErrorPatternAnalyzer
from auto_repair_engine import AutoRepairEngine

class RealtimeRepairController:
    def __init__(self):
        self.base_path = Path(__file__).parent
        self.project_root = self.base_path.parent
        
        # ãƒ­ã‚°è¨­å®š
        self.setup_logging()
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.github_monitor = GitHubActionsMonitor()
        self.pattern_analyzer = ErrorPatternAnalyzer()
        self.repair_engine = AutoRepairEngine()
        
        # åˆ¶å¾¡ãƒ•ãƒ©ã‚°
        self.running = False
        self.repair_in_progress = False
        
        # è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.config = {
            "check_interval": 30,  # 30ç§’é–“éš”
            "max_repair_cycles": 10,  # æœ€å¤§ä¿®å¾©ã‚µã‚¤ã‚¯ãƒ«æ•°
            "error_threshold": 0,  # ã‚¨ãƒ©ãƒ¼è¨±å®¹æ•°
            "consecutive_clean_required": 3,  # é€£ç¶šã‚¯ãƒªãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯è¦æ±‚æ•°
            "repair_timeout": 1800,  # ä¿®å¾©ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ30åˆ†ï¼‰
            "success_notification": True,
            "failure_notification": True
        }
        
        # çŠ¶æ…‹è¿½è·¡
        self.state = {
            "start_time": None,
            "total_cycles": 0,
            "repair_cycles": 0,
            "consecutive_clean_checks": 0,
            "last_error_count": 0,
            "errors_detected": [],
            "repair_history": [],
            "current_status": "stopped"
        }
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š
        self.setup_signal_handlers()
        
        self.logger.info("Realtime Repair Controller initialized")

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        log_file = self.base_path / "realtime_repair_controller.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger("RealtimeRepairController")

    def setup_signal_handlers(self):
        """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š"""
        def signal_handler(signum, frame):
            self.logger.info(f"Received signal {signum}, shutting down gracefully...")
            self.stop()
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

    async def check_github_actions_status(self) -> Dict[str, Any]:
        """GitHub Actionsã®çŠ¶æ³ãƒã‚§ãƒƒã‚¯"""
        try:
            # GitHub CLIèªè¨¼ç¢ºèª
            if not await self.github_monitor.check_gh_auth():
                return {
                    "status": "error",
                    "message": "GitHub CLI not authenticated",
                    "errors": [],
                    "total_errors": 0
                }
            
            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚’å–å¾—
            workflow_runs = await self.github_monitor.get_workflow_runs()
            
            if not workflow_runs:
                return {
                    "status": "no_runs",
                    "message": "No workflow runs found",
                    "errors": [],
                    "total_errors": 0
                }
            
            # å¤±æ•—ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’åˆ†æ
            failed_runs = [run for run in workflow_runs if run["conclusion"] == "failure"]
            in_progress_runs = [run for run in workflow_runs if run["status"] == "in_progress"]
            
            all_errors = []
            total_error_count = 0
            
            for run in failed_runs:
                run_id = run["id"]
                run_name = run["name"]
                
                # ãƒ­ã‚°ã‚’å–å¾—ã—ã¦åˆ†æ
                logs = await self.github_monitor.get_workflow_logs(str(run_id))
                if logs:
                    matches = self.pattern_analyzer.analyze_log_content(logs, f"workflow_{run_id}.log")
                    
                    for match in matches:
                        all_errors.append({
                            "workflow_id": run_id,
                            "workflow_name": run_name,
                            "pattern": match.pattern.name,
                            "category": match.pattern.category,
                            "severity": match.pattern.severity,
                            "confidence": match.confidence,
                            "matched_text": match.matched_text,
                            "line_number": match.line_number,
                            "auto_fixable": match.pattern.auto_fixable,
                            "timestamp": match.timestamp.isoformat()
                        })
                        total_error_count += 1
            
            return {
                "status": "success",
                "message": f"Found {len(failed_runs)} failed runs, {total_error_count} errors",
                "errors": all_errors,
                "total_errors": total_error_count,
                "failed_runs": len(failed_runs),
                "in_progress_runs": len(in_progress_runs),
                "workflow_runs": workflow_runs[:5]  # æœ€æ–°5ä»¶ã®ã¿
            }
            
        except Exception as e:
            self.logger.error(f"Error checking GitHub Actions status: {e}")
            return {
                "status": "error",
                "message": str(e),
                "errors": [],
                "total_errors": 0
            }

    async def execute_repair_cycle(self, errors: List[Dict]) -> Dict[str, Any]:
        """ä¿®å¾©ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œ"""
        if self.repair_in_progress:
            return {
                "status": "skipped",
                "message": "Repair already in progress"
            }
        
        self.repair_in_progress = True
        repair_start_time = datetime.now()
        
        try:
            self.logger.info(f"ğŸ”§ Starting repair cycle for {len(errors)} errors")
            
            # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ä¿®å¾©å¯¾è±¡ã‚’æ±ºå®š
            error_patterns = [error["matched_text"] for error in errors]
            unique_patterns = list(set(error_patterns))
            
            # ã‚¹ãƒãƒ¼ãƒˆä¿®å¾©å®Ÿè¡Œ
            repair_results = await self.repair_engine.smart_repair(unique_patterns)
            
            # ä¿®å¾©å¾Œã®æ¤œè¨¼
            await asyncio.sleep(5)  # ä¿®å¾©å®Œäº†ã‚’å¾…æ©Ÿ
            
            # ä¿®å¾©çµæœã®åˆ†æ
            total_actions = sum(len(category_results) for category_results in repair_results.values())
            successful_actions = sum(
                len([r for r in category_results if r.status.value == "success"])
                for category_results in repair_results.values()
            )
            
            success_rate = successful_actions / total_actions if total_actions > 0 else 0
            repair_duration = (datetime.now() - repair_start_time).total_seconds()
            
            # ä¿®å¾©å±¥æ­´ã«è¨˜éŒ²
            repair_record = {
                "timestamp": repair_start_time.isoformat(),
                "duration": repair_duration,
                "errors_addressed": len(errors),
                "repair_actions": total_actions,
                "successful_actions": successful_actions,
                "success_rate": success_rate,
                "categories": list(repair_results.keys())
            }
            
            self.state["repair_history"].append(repair_record)
            self.state["repair_cycles"] += 1
            
            # ä¿®å¾©å¾Œã«GitHub Actionsã‚’å†å®Ÿè¡Œ
            await self.trigger_github_actions_rerun()
            
            self.logger.info(f"âœ… Repair cycle completed: {success_rate:.2%} success rate")
            
            return {
                "status": "completed",
                "message": f"Repair cycle completed with {success_rate:.2%} success rate",
                "repair_results": repair_results,
                "statistics": repair_record
            }
            
        except Exception as e:
            self.logger.error(f"Error in repair cycle: {e}")
            return {
                "status": "error",
                "message": str(e),
                "repair_results": {}
            }
        finally:
            self.repair_in_progress = False

    async def trigger_github_actions_rerun(self):
        """GitHub Actionsãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å†å®Ÿè¡Œ"""
        try:
            # æœ€æ–°ã®å¤±æ•—ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å–å¾—
            workflow_runs = await self.github_monitor.get_workflow_runs()
            failed_runs = [run for run in workflow_runs if run["conclusion"] == "failure"]
            
            if failed_runs:
                latest_failed = failed_runs[0]  # æœ€æ–°ã®å¤±æ•—ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
                run_id = str(latest_failed["id"])
                
                success = await self.github_monitor.trigger_workflow_rerun(run_id)
                if success:
                    self.logger.info(f"ğŸ”„ Triggered rerun for workflow {run_id}")
                else:
                    self.logger.warning(f"Failed to trigger rerun for workflow {run_id}")
        
        except Exception as e:
            self.logger.error(f"Error triggering workflow rerun: {e}")

    async def save_state(self):
        """ç¾åœ¨ã®çŠ¶æ…‹ã‚’ä¿å­˜"""
        state_file = self.base_path / "realtime_repair_state.json"
        
        current_state = {
            "timestamp": datetime.now().isoformat(),
            "config": self.config,
            "state": self.state,
            "uptime": (datetime.now() - self.state["start_time"]).total_seconds() if self.state["start_time"] else 0
        }
        
        with open(state_file, 'w') as f:
            json.dump(current_state, f, indent=2)

    async def generate_status_report(self) -> Dict[str, Any]:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        uptime = (datetime.now() - self.state["start_time"]).total_seconds() if self.state["start_time"] else 0
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "status": self.state["current_status"],
            "uptime_seconds": uptime,
            "uptime_formatted": str(timedelta(seconds=int(uptime))),
            "total_cycles": self.state["total_cycles"],
            "repair_cycles": self.state["repair_cycles"],
            "consecutive_clean_checks": self.state["consecutive_clean_checks"],
            "last_error_count": self.state["last_error_count"],
            "errors_detected_count": len(self.state["errors_detected"]),
            "repair_success_rate": self.calculate_repair_success_rate(),
            "config": self.config,
            "recent_repairs": self.state["repair_history"][-5:] if self.state["repair_history"] else []
        }
        
        return report

    def calculate_repair_success_rate(self) -> float:
        """ä¿®å¾©æˆåŠŸç‡ã‚’è¨ˆç®—"""
        if not self.state["repair_history"]:
            return 0.0
        
        total_success_rate = sum(record["success_rate"] for record in self.state["repair_history"])
        return total_success_rate / len(self.state["repair_history"])

    async def main_control_loop(self):
        """ãƒ¡ã‚¤ãƒ³åˆ¶å¾¡ãƒ«ãƒ¼ãƒ—"""
        self.logger.info("ğŸš€ Starting realtime repair control loop")
        self.running = True
        self.state["start_time"] = datetime.now()
        self.state["current_status"] = "monitoring"
        
        try:
            while self.running:
                cycle_start_time = datetime.now()
                self.state["total_cycles"] += 1
                
                self.logger.info(f"ğŸ“Š Control cycle {self.state['total_cycles']} starting")
                
                try:
                    # GitHub Actionsã®çŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯
                    actions_status = await self.check_github_actions_status()
                    
                    if actions_status["status"] == "error":
                        self.logger.error(f"GitHub Actions check failed: {actions_status['message']}")
                        await asyncio.sleep(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾…æ©Ÿ
                        continue
                    
                    total_errors = actions_status["total_errors"]
                    errors = actions_status["errors"]
                    
                    self.state["last_error_count"] = total_errors
                    self.state["errors_detected"] = errors
                    
                    if total_errors <= self.config["error_threshold"]:
                        # ã‚¨ãƒ©ãƒ¼ãªã— - ã‚¯ãƒªãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
                        self.state["consecutive_clean_checks"] += 1
                        self.logger.info(f"âœ… Clean check {self.state['consecutive_clean_checks']}/{self.config['consecutive_clean_required']}")
                        
                        if self.state["consecutive_clean_checks"] >= self.config["consecutive_clean_required"]:
                            # æˆåŠŸé”æˆï¼
                            self.logger.info("ğŸ‰ SUCCESS! No errors detected for required consecutive checks")
                            self.state["current_status"] = "success"
                            
                            if self.config["success_notification"]:
                                await self.send_success_notification()
                            
                            # æˆåŠŸçŠ¶æ…‹ã‚’ä¿å­˜
                            await self.save_state()
                            break  # ãƒ«ãƒ¼ãƒ—çµ‚äº†
                    else:
                        # ã‚¨ãƒ©ãƒ¼æ¤œå‡º - ä¿®å¾©å®Ÿè¡Œ
                        self.state["consecutive_clean_checks"] = 0
                        self.logger.warning(f"âŒ Detected {total_errors} errors, starting repair cycle")
                        
                        if self.state["repair_cycles"] < self.config["max_repair_cycles"]:
                            self.state["current_status"] = "repairing"
                            repair_result = await self.execute_repair_cycle(errors)
                            
                            if repair_result["status"] == "completed":
                                self.logger.info("ğŸ”§ Repair cycle completed, waiting for verification")
                                # ä¿®å¾©å¾Œã¯å°‘ã—é•·ã‚ã«å¾…æ©Ÿã—ã¦ã‹ã‚‰ãƒã‚§ãƒƒã‚¯
                                await asyncio.sleep(60)
                            else:
                                self.logger.error(f"Repair cycle failed: {repair_result['message']}")
                        else:
                            # æœ€å¤§ä¿®å¾©å›æ•°ã«é”ã—ãŸ
                            self.logger.error(f"âŒ Maximum repair cycles ({self.config['max_repair_cycles']}) reached")
                            self.state["current_status"] = "max_repairs_reached"
                            
                            if self.config["failure_notification"]:
                                await self.send_failure_notification(total_errors, errors)
                            
                            break  # ãƒ«ãƒ¼ãƒ—çµ‚äº†
                    
                    # çŠ¶æ…‹ã‚’ä¿å­˜
                    await self.save_state()
                    
                    # æ¬¡ã®ãƒã‚§ãƒƒã‚¯ã¾ã§å¾…æ©Ÿ
                    if self.running:
                        self.state["current_status"] = "monitoring"
                        await asyncio.sleep(self.config["check_interval"])
                
                except Exception as e:
                    self.logger.error(f"Error in control loop cycle: {e}")
                    self.logger.debug(traceback.format_exc())
                    await asyncio.sleep(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾…æ©Ÿ
                
                cycle_duration = (datetime.now() - cycle_start_time).total_seconds()
                self.logger.debug(f"Cycle {self.state['total_cycles']} completed in {cycle_duration:.2f}s")
        
        except KeyboardInterrupt:
            self.logger.info("Control loop interrupted by user")
        except Exception as e:
            self.logger.error(f"Fatal error in control loop: {e}")
            self.logger.debug(traceback.format_exc())
        finally:
            self.running = False
            self.state["current_status"] = "stopped"
            await self.save_state()
            self.logger.info("Control loop stopped")

    async def send_success_notification(self):
        """æˆåŠŸé€šçŸ¥ã‚’é€ä¿¡"""
        self.logger.info("ğŸ“§ Sending success notification")
        
        # å®Ÿéš›ã®é€šçŸ¥å®Ÿè£…ï¼ˆSlackã€ãƒ¡ãƒ¼ãƒ«ç­‰ï¼‰ã¯ã“ã“ã«è¿½åŠ 
        success_message = f"""
ğŸ‰ ITSM Auto-Repair SUCCESS!

âœ… All GitHub Actions errors have been resolved
ğŸ“Š Total cycles: {self.state['total_cycles']}
ğŸ”§ Repair cycles: {self.state['repair_cycles']}
â±ï¸ Uptime: {str(timedelta(seconds=int((datetime.now() - self.state['start_time']).total_seconds())))}
ğŸ“ˆ Repair success rate: {self.calculate_repair_success_rate():.2%}

The system will continue monitoring for new issues.
        """
        
        print(success_message)

    async def send_failure_notification(self, error_count: int, errors: List[Dict]):
        """å¤±æ•—é€šçŸ¥ã‚’é€ä¿¡"""
        self.logger.warning("ğŸ“§ Sending failure notification")
        
        error_summary = {}
        for error in errors:
            category = error["category"]
            if category not in error_summary:
                error_summary[category] = 0
            error_summary[category] += 1
        
        failure_message = f"""
âŒ ITSM Auto-Repair FAILED

ğŸš¨ Unable to resolve all errors after maximum repair attempts
ğŸ“Š Remaining errors: {error_count}
ğŸ”§ Repair cycles attempted: {self.state['repair_cycles']}
â±ï¸ Total runtime: {str(timedelta(seconds=int((datetime.now() - self.state['start_time']).total_seconds())))}

Error breakdown:
{json.dumps(error_summary, indent=2)}

Manual intervention may be required.
        """
        
        print(failure_message)

    def stop(self):
        """åˆ¶å¾¡ãƒ«ãƒ¼ãƒ—ã‚’åœæ­¢"""
        self.logger.info("Stopping realtime repair controller...")
        self.running = False

    async def start(self):
        """åˆ¶å¾¡ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹"""
        await self.main_control_loop()


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 80)
    print("ğŸ¤– ITSM GitHub Actions Realtime Error Monitor & Auto-Repair System")
    print("ğŸ¯ Target: 0 errors with 3 consecutive clean checks")
    print("âš¡ Real-time monitoring with 30-second intervals")  
    print("ğŸ”§ Automatic repair with smart pattern matching")
    print("ğŸš€ Repository: Kensan196948G/ITSM-ITManagementSystem")
    print("=" * 80)
    
    controller = RealtimeRepairController()
    
    try:
        # åˆæœŸçŠ¶æ…‹ãƒ¬ãƒãƒ¼ãƒˆ
        initial_report = await controller.generate_status_report()
        print(f"ğŸ“Š Initial Status: {json.dumps(initial_report, indent=2)}")
        
        # ãƒ¡ã‚¤ãƒ³åˆ¶å¾¡ãƒ«ãƒ¼ãƒ—é–‹å§‹
        await controller.start()
        
        # æœ€çµ‚çŠ¶æ…‹ãƒ¬ãƒãƒ¼ãƒˆ
        final_report = await controller.generate_status_report()
        print(f"ğŸ“Š Final Status: {json.dumps(final_report, indent=2)}")
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ System stopped by user")
        controller.stop()
    except Exception as e:
        print(f"âŒ Fatal system error: {e}")
        controller.stop()


if __name__ == "__main__":
    asyncio.run(main())