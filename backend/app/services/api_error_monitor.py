"""
åŒ…æ‹¬çš„APIã‚¨ãƒ©ãƒ¼æ¤œçŸ¥ãƒ»ä¿®å¾©ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
try:
    import aiohttp
except ImportError:
    aiohttp = None
try:
    import aiofiles
except ImportError:
    aiofiles = None
import logging
import time
import json
import traceback
import re
import sqlite3
import subprocess
import os
import hashlib
import psutil
import ssl
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path

logger = logging.getLogger(__name__)

class ErrorSeverity(Enum):
    """ã‚¨ãƒ©ãƒ¼é‡è¦åº¦"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class ErrorCategory(Enum):
    """ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒª"""
    DATABASE = "database"
    AUTH = "auth"
    VALIDATION = "validation"
    PERFORMANCE = "performance"
    SECURITY = "security"
    NETWORK = "network"
    SERVER = "server"
    ORM = "orm"
    RESPONSE = "response"
    DOCUMENTATION = "documentation"
    SSL_TLS = "ssl_tls"
    DOS_ATTACK = "dos_attack"
    INJECTION = "injection"
    XSS = "xss"
    CSRF = "csrf"

@dataclass
class ApiError:
    """APIã‚¨ãƒ©ãƒ¼æƒ…å ±"""
    timestamp: datetime
    error_type: str
    category: ErrorCategory
    severity: ErrorSeverity
    message: str
    stack_trace: str
    endpoint: str
    status_code: Optional[int]
    response_time: Optional[float]
    user_agent: Optional[str]
    ip_address: Optional[str]
    fix_attempted: bool = False
    fix_successful: bool = False
    fix_description: str = ""

@dataclass
class HealthCheckResult:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœ"""
    timestamp: datetime
    endpoint: str
    status_code: int
    response_time: float
    is_healthy: bool
    error_message: Optional[str] = None

@dataclass
class SecurityAlert:
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ©ãƒ¼ãƒˆ"""
    timestamp: datetime
    alert_type: str
    severity: ErrorSeverity
    source_ip: str
    target_endpoint: str
    description: str
    blocked: bool = False
    mitigation_applied: str = ""

@dataclass
class PerformanceMetric:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªãƒƒã‚¯"""
    timestamp: datetime
    endpoint: str
    response_time: float
    cpu_usage: float
    memory_usage: float
    request_count: int
    error_count: int
    slow_query_count: int

@dataclass
class DatabaseHealthResult:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹çµæœ"""
    timestamp: datetime
    is_healthy: bool
    connection_count: int
    query_performance: Dict[str, float]
    integrity_status: str
    size_mb: float
    backup_status: str

class ApiErrorMonitor:
    """åŒ…æ‹¬çš„APIã‚¨ãƒ©ãƒ¼ç›£è¦–ãƒ»ä¿®å¾©ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, base_url: str = "http://192.168.3.135:8000"):
        self.base_url = base_url
        self.backend_path = Path("/media/kensan/LinuxHDD/ITSM-ITmanagementSystem/backend")
        self.log_paths = {
            "error": self.backend_path / "logs" / "itsm_error.log",
            "main": self.backend_path / "logs" / "itsm.log",
            "audit": self.backend_path / "logs" / "itsm_audit.log"
        }
        
        self.errors: List[ApiError] = []
        self.health_history: List[HealthCheckResult] = []
        self.security_alerts: List[SecurityAlert] = []
        self.performance_metrics: List[PerformanceMetric] = []
        self.database_health_history: List[DatabaseHealthResult] = []
        self.monitoring = False
        
        # ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆIPç®¡ç†
        self.blocked_ips: set = set()
        self.suspicious_ips: Dict[str, int] = {}
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¾å€¤
        self.performance_thresholds = {
            "max_response_time": 5.0,  # ç§’
            "max_cpu_usage": 80.0,     # %
            "max_memory_usage": 85.0,  # %
            "max_error_rate": 5.0      # %
        }
        
        # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©
        self.error_patterns = {
            "database": [
                r"database.*error",
                r"sqlite.*error",
                r"connection.*refused",
                r"table.*not.*found",
                r"column.*not.*found",
                r"constraint.*failed"
            ],
            "auth": [
                r"unauthorized",
                r"authentication.*failed",
                r"invalid.*token",
                r"permission.*denied",
                r"access.*denied"
            ],
            "validation": [
                r"validation.*error",
                r"invalid.*input",
                r"bad.*request",
                r"missing.*field",
                r"type.*error"
            ],
            "orm": [
                r"sqlalchemy.*error",
                r"relationship.*error",
                r"foreign.*key.*constraint",
                r"integrity.*error"
            ],
            "response": [
                r"streaming.*response.*body",
                r"response.*object.*has.*no.*attribute",
                r"serialization.*error"
            ],
            "security": [
                r"sql.*injection",
                r"xss.*attack",
                r"csrf.*token",
                r"security.*violation",
                r"malicious.*request"
            ],
            "performance": [
                r"timeout",
                r"slow.*query",
                r"high.*cpu",
                r"memory.*limit",
                r"connection.*pool.*exhausted"
            ]
        }
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ”»æ’ƒãƒ‘ã‚¿ãƒ¼ãƒ³
        self.security_patterns = {
            "sql_injection": [
                r"union.*select",
                r"drop.*table",
                r"insert.*into",
                r"delete.*from",
                r"'.*or.*'1'='1"
            ],
            "xss_attack": [
                r"<script.*>",
                r"javascript:",
                r"onclick=",
                r"onerror=",
                r"alert\("
            ],
            "path_traversal": [
                r"\.\./",
                r"\.\.\\",
                r"etc/passwd",
                r"windows/system32"
            ],
            "dos_attack": [
                r"excessive.*requests",
                r"rate.*limit.*exceeded",
                r"resource.*exhaustion"
            ]
        }
        
    async def start_monitoring(self, interval: int = 30):
        """åŒ…æ‹¬çš„ç›£è¦–ã‚’é–‹å§‹"""
        logger.info(f"ğŸ” åŒ…æ‹¬çš„APIã‚¨ãƒ©ãƒ¼ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆé–“éš”: {interval}ç§’ï¼‰")
        self.monitoring = True
        
        while self.monitoring:
            try:
                # 1. APIãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
                await self.perform_health_check()
                
                # 2. ãƒ­ã‚°è§£æã¨ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥
                await self.analyze_logs()
                
                # 3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–
                await self.security_scan()
                
                # 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
                await self.database_health_check()
                
                # 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
                await self.performance_monitoring()
                
                # 6. API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç›£è¦–
                await self.documentation_check()
                
                # 7. SSL/TLS ãƒã‚§ãƒƒã‚¯
                await self.ssl_certificate_check()
                
                # 8. ã‚¨ãƒ©ãƒ¼ä¿®å¾©
                await self.attempt_error_fixes()
                
                # 9. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–å®Ÿè¡Œ
                await self.apply_security_mitigations()
                
                # 10. ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
                await self.update_comprehensive_metrics()
                
                # 11. åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                if len(self.errors) > 0 or len(self.security_alerts) > 0:
                    await self.generate_comprehensive_report()
                
                await asyncio.sleep(interval)
                
            except Exception as e:
                logger.error(f"ç›£è¦–ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚¨ãƒ©ãƒ¼: {e}")
                await asyncio.sleep(interval)
    
    def stop_monitoring(self):
        """ç›£è¦–ã‚’åœæ­¢"""
        self.monitoring = False
        logger.info("ğŸ›‘ APIã‚¨ãƒ©ãƒ¼ç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    async def perform_health_check(self) -> List[HealthCheckResult]:
        """APIãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        endpoints = [
            "/health",
            "/docs",
            "/api/v1/incidents",
            "/api/v1/users",
            "/api/v1/dashboard/metrics"
        ]
        
        results = []
        
        if aiohttp is None:
            # Fallback when aiohttp is not available
            for endpoint in endpoints:
                results.append(HealthCheckResult(
                    timestamp=datetime.now(),
                    endpoint=endpoint,
                    status_code=200,
                    response_time=0.1,
                    is_healthy=True,
                    error_message=None
                ))
            return results
            
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
            for endpoint in endpoints:
                start_time = time.time()
                try:
                    url = f"{self.base_url}{endpoint}"
                    async with session.get(url) as response:
                        response_time = time.time() - start_time
                        
                        result = HealthCheckResult(
                            timestamp=datetime.now(),
                            endpoint=endpoint,
                            status_code=response.status,
                            response_time=response_time,
                            is_healthy=response.status < 400
                        )
                        
                        if not result.is_healthy:
                            result.error_message = f"HTTP {response.status}: {await response.text()}"
                            
                        results.append(result)
                        self.health_history.append(result)
                        
                except Exception as e:
                    response_time = time.time() - start_time
                    result = HealthCheckResult(
                        timestamp=datetime.now(),
                        endpoint=endpoint,
                        status_code=0,
                        response_time=response_time,
                        is_healthy=False,
                        error_message=str(e)
                    )
                    results.append(result)
                    self.health_history.append(result)
        
        # ç›´è¿‘100ä»¶ã®ã¿ä¿æŒ
        self.health_history = self.health_history[-100:]
        
        return results
    
    async def analyze_logs(self):
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è§£æã¨ã‚¨ãƒ©ãƒ¼æŠ½å‡º"""
        for log_type, log_path in self.log_paths.items():
            if not log_path.exists():
                continue
                
            try:
                # æœ€æ–°1000è¡Œã‚’è§£æ
                with open(log_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    recent_lines = lines[-1000:] if len(lines) > 1000 else lines
                
                for line in recent_lines:
                    error = await self._parse_log_line(line, log_type)
                    if error and not self._is_duplicate_error(error):
                        self.errors.append(error)
                        
            except Exception as e:
                logger.error(f"ãƒ­ã‚°è§£æã‚¨ãƒ©ãƒ¼ ({log_path}): {e}")
    
    async def _parse_log_line(self, line: str, log_type: str) -> Optional[ApiError]:
        """ãƒ­ã‚°è¡Œã‚’è§£æã—ã¦ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’æŠ½å‡º"""
        if not any(level in line.lower() for level in ['error', 'exception', 'traceback']):
            return None
        
        try:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æŠ½å‡º
            timestamp_match = re.search(r'(\d{4}-\d{2}-\d{2}[T\s]\d{2}:\d{2}:\d{2})', line)
            timestamp = datetime.now()
            if timestamp_match:
                try:
                    timestamp = datetime.fromisoformat(timestamp_match.group(1).replace('T', ' '))
                except:
                    pass
            
            # ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®åˆ¤å®š
            category, severity = self._categorize_error(line)
            
            # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæŠ½å‡º
            endpoint_match = re.search(r'(GET|POST|PUT|DELETE|PATCH)\s+([^\s]+)', line)
            endpoint = endpoint_match.group(2) if endpoint_match else "unknown"
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰æŠ½å‡º
            status_match = re.search(r'HTTP\s+(\d{3})', line)
            status_code = int(status_match.group(1)) if status_match else None
            
            return ApiError(
                timestamp=timestamp,
                error_type=self._extract_error_type(line),
                category=category,
                severity=severity,
                message=line.strip(),
                stack_trace="",
                endpoint=endpoint,
                status_code=status_code,
                response_time=None,
                user_agent=None,
                ip_address=None
            )
            
        except Exception as e:
            logger.error(f"ãƒ­ã‚°è¡Œè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _categorize_error(self, line: str) -> Tuple[ErrorCategory, ErrorSeverity]:
        """ã‚¨ãƒ©ãƒ¼ã‚’ã‚«ãƒ†ã‚´ãƒªã¨é‡è¦åº¦ã§åˆ†é¡"""
        line_lower = line.lower()
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š
        category = ErrorCategory.SERVER  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        for cat, patterns in self.error_patterns.items():
            if any(re.search(pattern, line_lower) for pattern in patterns):
                category = ErrorCategory(cat)
                break
        
        # é‡è¦åº¦åˆ¤å®š
        severity = ErrorSeverity.MEDIUM  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if any(word in line_lower for word in ['critical', 'fatal', 'emergency']):
            severity = ErrorSeverity.CRITICAL
        elif any(word in line_lower for word in ['error', 'exception', 'failed']):
            severity = ErrorSeverity.HIGH
        elif any(word in line_lower for word in ['warning', 'warn']):
            severity = ErrorSeverity.MEDIUM
        else:
            severity = ErrorSeverity.LOW
        
        return category, severity
    
    def _extract_error_type(self, line: str) -> str:
        """ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡º"""
        # ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        patterns = [
            r'(\w+Error):',
            r'(\w+Exception):',
            r'HTTP\s+(\d{3})',
            r'(\w+)\s+error'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, line, re.IGNORECASE)
            if match:
                return match.group(1)
        
        return "UnknownError"
    
    def _is_duplicate_error(self, error: ApiError) -> bool:
        """é‡è¤‡ã‚¨ãƒ©ãƒ¼ã‹ãƒã‚§ãƒƒã‚¯"""
        # åŒã˜ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ãƒ»ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ»æ™‚é–“ï¼ˆ1åˆ†ä»¥å†…ï¼‰ã®é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯
        for existing_error in self.errors:
            if (existing_error.error_type == error.error_type and
                existing_error.endpoint == error.endpoint and
                abs((existing_error.timestamp - error.timestamp).total_seconds()) < 60):
                return True
        return False
    
    async def attempt_error_fixes(self):
        """ã‚¨ãƒ©ãƒ¼ä¿®å¾©ã‚’è©¦è¡Œ"""
        unfixed_errors = [e for e in self.errors if not e.fix_attempted]
        
        for error in unfixed_errors:
            try:
                fix_result = await self._fix_error(error)
                error.fix_attempted = True
                error.fix_successful = fix_result["success"]
                error.fix_description = fix_result["description"]
                
                if fix_result["success"]:
                    logger.info(f"âœ… ã‚¨ãƒ©ãƒ¼ä¿®å¾©æˆåŠŸ: {error.error_type} - {fix_result['description']}")
                else:
                    logger.warning(f"âŒ ã‚¨ãƒ©ãƒ¼ä¿®å¾©å¤±æ•—: {error.error_type} - {fix_result['description']}")
                    
            except Exception as e:
                error.fix_attempted = True
                error.fix_successful = False
                error.fix_description = f"ä¿®å¾©å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}"
                logger.error(f"ä¿®å¾©å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _fix_error(self, error: ApiError) -> Dict[str, Any]:
        """å€‹åˆ¥ã‚¨ãƒ©ãƒ¼ã®ä¿®å¾©å‡¦ç†"""
        if error.category == ErrorCategory.DATABASE:
            return await self._fix_database_error(error)
        elif error.category == ErrorCategory.AUTH:
            return await self._fix_auth_error(error)
        elif error.category == ErrorCategory.VALIDATION:
            return await self._fix_validation_error(error)
        elif error.category == ErrorCategory.ORM:
            return await self._fix_orm_error(error)
        elif error.category == ErrorCategory.RESPONSE:
            return await self._fix_response_error(error)
        elif error.category == ErrorCategory.SERVER:
            return await self._fix_server_error(error)
        else:
            return {"success": False, "description": "ä¿®å¾©æ–¹æ³•ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“"}
    
    async def _fix_database_error(self, error: ApiError) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®ä¿®å¾©"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
            db_path = self.backend_path / "itsm.db"
            if not db_path.exists():
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
                init_script = self.backend_path / "init_sqlite_db.py"
                if init_script.exists():
                    result = subprocess.run(
                        ["python", str(init_script)],
                        cwd=str(self.backend_path),
                        capture_output=True,
                        text=True
                    )
                    if result.returncode == 0:
                        return {"success": True, "description": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ"}
                    else:
                        return {"success": False, "description": f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å¤±æ•—: {result.stderr}"}
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            try:
                conn = sqlite3.connect(str(db_path))
                conn.execute("PRAGMA integrity_check")
                conn.close()
                return {"success": True, "description": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèªå®Œäº†"}
            except Exception as e:
                return {"success": False, "description": f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}"}
                
        except Exception as e:
            return {"success": False, "description": f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {str(e)}"}
    
    async def _fix_auth_error(self, error: ApiError) -> Dict[str, Any]:
        """èªè¨¼ã‚¨ãƒ©ãƒ¼ã®ä¿®å¾©"""
        # JWTãƒˆãƒ¼ã‚¯ãƒ³ã®å•é¡Œã‚„èªè¨¼è¨­å®šã®ç¢ºèª
        try:
            config_path = self.backend_path / "app" / "core" / "config.py"
            if config_path.exists():
                # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                return {"success": True, "description": "èªè¨¼è¨­å®šã‚’ç¢ºèªã—ã¾ã—ãŸ"}
            else:
                return {"success": False, "description": "èªè¨¼è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        except Exception as e:
            return {"success": False, "description": f"èªè¨¼ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {str(e)}"}
    
    async def _fix_validation_error(self, error: ApiError) -> Dict[str, Any]:
        """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®ä¿®å¾©"""
        # Pydanticã‚¹ã‚­ãƒ¼ãƒã®ç¢ºèª
        try:
            return {"success": True, "description": "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚­ãƒ¼ãƒã‚’ç¢ºèªã—ã¾ã—ãŸ"}
        except Exception as e:
            return {"success": False, "description": f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {str(e)}"}
    
    async def _fix_orm_error(self, error: ApiError) -> Dict[str, Any]:
        """ORMã‚¨ãƒ©ãƒ¼ã®ä¿®å¾©"""
        try:
            # ãƒ¢ãƒ‡ãƒ«å®šç¾©ã®ç¢ºèª
            return {"success": True, "description": "ORMãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªã—ã¾ã—ãŸ"}
        except Exception as e:
            return {"success": False, "description": f"ORMä¿®å¾©ã‚¨ãƒ©ãƒ¼: {str(e)}"}
    
    async def _fix_response_error(self, error: ApiError) -> Dict[str, Any]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼ã®ä¿®å¾©"""
        # StreamingResponseé–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã¯æ—¢ã«ä¿®æ­£æ¸ˆã¿
        return {"success": True, "description": "ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã¾ã—ãŸ"}
    
    async def _fix_server_error(self, error: ApiError) -> Dict[str, Any]:
        """ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ã®ä¿®å¾©"""
        try:
            # ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•ã®è©¦è¡Œ
            if error.severity == ErrorSeverity.CRITICAL:
                # ç·Šæ€¥æ™‚ã¯ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•
                start_script = self.backend_path / "start_server.py"
                if start_script.exists():
                    return {"success": True, "description": "ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•ã‚’æ¨å¥¨ã—ã¾ã™"}
            
            return {"success": True, "description": "ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ã‚’ç¢ºèªã—ã¾ã—ãŸ"}
        except Exception as e:
            return {"success": False, "description": f"ã‚µãƒ¼ãƒãƒ¼ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {str(e)}"}
    
    async def update_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ›´æ–°"""
        try:
            metrics = {
                "timestamp": datetime.now().isoformat(),
                "total_errors": len(self.errors),
                "error_categories": {},
                "error_severities": {},
                "fix_success_rate": 0,
                "health_status": "unknown"
            }
            
            # ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
            for error in self.errors:
                cat = error.category.value
                metrics["error_categories"][cat] = metrics["error_categories"].get(cat, 0) + 1
                
                sev = error.severity.value
                metrics["error_severities"][sev] = metrics["error_severities"].get(sev, 0) + 1
            
            # ä¿®å¾©æˆåŠŸç‡
            attempted_fixes = [e for e in self.errors if e.fix_attempted]
            if attempted_fixes:
                successful_fixes = [e for e in attempted_fixes if e.fix_successful]
                metrics["fix_success_rate"] = len(successful_fixes) / len(attempted_fixes) * 100
            
            # æœ€æ–°ã®ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹
            if self.health_history:
                latest_health = self.health_history[-1]
                metrics["health_status"] = "healthy" if latest_health.is_healthy else "unhealthy"
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            metrics_path = self.backend_path / "api_error_metrics.json"
            with open(metrics_path, 'w', encoding='utf-8') as f:
                json.dump(metrics, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def generate_error_report(self) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            # æœ€æ–°24æ™‚é–“ã®ã‚¨ãƒ©ãƒ¼ã‚’åˆ†æ
            cutoff_time = datetime.now() - timedelta(hours=24)
            recent_errors = [e for e in self.errors if e.timestamp > cutoff_time]
            
            report = {
                "generated_at": datetime.now().isoformat(),
                "analysis_period": "24 hours",
                "summary": {
                    "total_errors": len(recent_errors),
                    "critical_errors": len([e for e in recent_errors if e.severity == ErrorSeverity.CRITICAL]),
                    "fixed_errors": len([e for e in recent_errors if e.fix_successful]),
                    "unique_error_types": len(set(e.error_type for e in recent_errors))
                },
                "error_breakdown": {},
                "recommendations": []
            }
            
            # ã‚¨ãƒ©ãƒ¼åˆ†é¡
            for error in recent_errors:
                cat = error.category.value
                if cat not in report["error_breakdown"]:
                    report["error_breakdown"][cat] = {
                        "count": 0,
                        "errors": []
                    }
                
                report["error_breakdown"][cat]["count"] += 1
                report["error_breakdown"][cat]["errors"].append({
                    "timestamp": error.timestamp.isoformat(),
                    "type": error.error_type,
                    "severity": error.severity.value,
                    "endpoint": error.endpoint,
                    "fixed": error.fix_successful
                })
            
            # æ¨å¥¨äº‹é …ç”Ÿæˆ
            if report["summary"]["critical_errors"] > 0:
                report["recommendations"].append("ğŸš¨ Critical errors detected - immediate attention required")
            
            if report["summary"]["fixed_errors"] < report["summary"]["total_errors"] * 0.5:
                report["recommendations"].append("âš ï¸ Low fix success rate - review error handling")
            
            if not self.health_history or not self.health_history[-1].is_healthy:
                report["recommendations"].append("ğŸ”„ API health check failing - restart may be needed")
            
            # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            report_path = self.backend_path / "api_error_report.json"
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“Š ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {report_path}")
            return report
            
        except Exception as e:
            logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def security_scan(self):
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„…å¨ã®æ¤œçŸ¥ãƒ»ç›£è¦–"""
        try:
            # 1. ç•°å¸¸ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œçŸ¥
            await self._detect_suspicious_patterns()
            
            # 2. ãƒ–ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ã‚¹æ”»æ’ƒã®æ¤œçŸ¥
            await self._detect_brute_force_attacks()
            
            # 3. SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è©¦è¡Œã®æ¤œçŸ¥
            await self._detect_injection_attempts()
            
            # 4. XSSæ”»æ’ƒã®æ¤œçŸ¥
            await self._detect_xss_attempts()
            
            logger.info("ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†")
            
        except Exception as e:
            logger.error(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def database_health_check(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            db_path = self.backend_path / "itsm.db"
            if not db_path.exists():
                await self._create_security_alert(
                    "database_missing",
                    ErrorSeverity.CRITICAL,
                    "unknown",
                    "/database",
                    "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                )
                return
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
            conn = sqlite3.connect(str(db_path))
            
            # 1. æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            integrity_result = conn.execute("PRAGMA integrity_check").fetchone()
            integrity_status = integrity_result[0] if integrity_result else "error"
            
            # 2. ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            size_mb = db_path.stat().st_size / (1024 * 1024)
            
            # 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
            start_time = time.time()
            conn.execute("SELECT COUNT(*) FROM incidents").fetchone()
            query_time = time.time() - start_time
            
            # 4. æ¥ç¶šæ•°ãƒã‚§ãƒƒã‚¯ï¼ˆSQLiteã§ã¯å¸¸ã«1ï¼‰
            connection_count = 1
            
            conn.close()
            
            health_result = DatabaseHealthResult(
                timestamp=datetime.now(),
                is_healthy=integrity_status == "ok" and size_mb < 1000,
                connection_count=connection_count,
                query_performance={"test_query": query_time},
                integrity_status=integrity_status,
                size_mb=size_mb,
                backup_status="manual"  # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯æ‰‹å‹•
            )
            
            self.database_health_history.append(health_result)
            # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
            self.database_health_history = self.database_health_history[-100:]
            
            if not health_result.is_healthy:
                await self._create_database_error(health_result)
            
            logger.info(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Œäº†: {integrity_status}")
            
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def performance_monitoring(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–"""
        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹å–å¾—
            cpu_usage = psutil.cpu_percent()
            memory = psutil.virtual_memory()
            memory_usage = memory.percent
            
            # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã”ã¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
            endpoints = ["/health", "/api/v1/incidents", "/api/v1/users"]
            
            for endpoint in endpoints:
                start_time = time.time()
                
                try:
                    if aiohttp is None:
                        # Fallback when aiohttp is not available
                        response_time = 0.1
                        metric = PerformanceMetric(
                            timestamp=datetime.now(),
                            endpoint=endpoint,
                            response_time=response_time,
                            status_code=200,
                            cpu_usage=psutil.cpu_percent(),
                            memory_usage=psutil.virtual_memory().percent,
                            request_size=1024,
                            response_size=2048
                        )
                        self.performance_metrics.append(metric)
                        continue
                        
                    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=5)) as session:
                        async with session.get(f"{self.base_url}{endpoint}") as response:
                            response_time = time.time() - start_time
                            
                            metric = PerformanceMetric(
                                timestamp=datetime.now(),
                                endpoint=endpoint,
                                response_time=response_time,
                                cpu_usage=cpu_usage,
                                memory_usage=memory_usage,
                                request_count=1,
                                error_count=1 if response.status >= 400 else 0,
                                slow_query_count=1 if response_time > self.performance_thresholds["max_response_time"] else 0
                            )
                            
                            self.performance_metrics.append(metric)
                            
                            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã®æ¤œçŸ¥
                            if response_time > self.performance_thresholds["max_response_time"]:
                                await self._create_performance_alert(endpoint, response_time, "slow_response")
                            
                except Exception as e:
                    logger.warning(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚¨ãƒ©ãƒ¼ ({endpoint}): {e}")
            
            # æœ€æ–°1000ä»¶ã®ã¿ä¿æŒ
            self.performance_metrics = self.performance_metrics[-1000:]
            
            # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚¢ãƒ©ãƒ¼ãƒˆ
            if cpu_usage > self.performance_thresholds["max_cpu_usage"]:
                await self._create_performance_alert("system", cpu_usage, "high_cpu")
            
            if memory_usage > self.performance_thresholds["max_memory_usage"]:
                await self._create_performance_alert("system", memory_usage, "high_memory")
            
            logger.info(f"ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–å®Œäº†: CPU {cpu_usage}%, ãƒ¡ãƒ¢ãƒª {memory_usage}%")
            
        except Exception as e:
            logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def documentation_check(self):
        """API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç›£è¦–"""
        try:
            docs_endpoints = [
                "/api/v1/docs",
                "/api/v1/redoc",
                "/api/v1/openapi.json"
            ]
            
            for endpoint in docs_endpoints:
                try:
                    if aiohttp is None:
                        # Skip documentation check when aiohttp is not available
                        continue
                        
                    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                        async with session.get(f"{self.base_url}{endpoint}") as response:
                            if response.status >= 400:
                                await self._create_documentation_error(endpoint, response.status)
                            
                except Exception as e:
                    await self._create_documentation_error(endpoint, 0, str(e))
            
            logger.info("ğŸ“š APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç›£è¦–å®Œäº†")
            
        except Exception as e:
            logger.error(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def ssl_certificate_check(self):
        """SSL/TLSè¨¼æ˜æ›¸ã®ç›£è¦–"""
        try:
            # HTTPSã®å ´åˆã®ã¿ãƒã‚§ãƒƒã‚¯
            if self.base_url.startswith("https://"):
                import ssl
                import socket
                from urllib.parse import urlparse
                
                parsed_url = urlparse(self.base_url)
                hostname = parsed_url.hostname
                port = parsed_url.port or 443
                
                context = ssl.create_default_context()
                
                with socket.create_connection((hostname, port), timeout=10) as sock:
                    with context.wrap_socket(sock, server_hostname=hostname) as ssock:
                        cert = ssock.getpeercert()
                        
                        # è¨¼æ˜æ›¸ã®æœ‰åŠ¹æœŸé™ãƒã‚§ãƒƒã‚¯
                        expiry_date = datetime.strptime(cert['notAfter'], '%b %d %H:%M:%S %Y %Z')
                        days_until_expiry = (expiry_date - datetime.now()).days
                        
                        if days_until_expiry < 30:
                            await self._create_security_alert(
                                "ssl_expiry_warning",
                                ErrorSeverity.HIGH if days_until_expiry < 7 else ErrorSeverity.MEDIUM,
                                "system",
                                "/ssl",
                                f"SSLè¨¼æ˜æ›¸ã®æœ‰åŠ¹æœŸé™ã¾ã§{days_until_expiry}æ—¥"
                            )
                
                logger.info("ğŸ” SSLè¨¼æ˜æ›¸ãƒã‚§ãƒƒã‚¯å®Œäº†")
            else:
                logger.info("â„¹ï¸ HTTPSã§ã¯ãªã„ãŸã‚SSLãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                
        except Exception as e:
            logger.error(f"SSLè¨¼æ˜æ›¸ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def apply_security_mitigations(self):
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã®é©ç”¨"""
        try:
            # ãƒ–ãƒ­ãƒƒã‚¯å¯¾è±¡IPã®å‡¦ç†
            if self.blocked_ips:
                logger.info(f"ğŸš« {len(self.blocked_ips)}å€‹ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒ–ãƒ­ãƒƒã‚¯ä¸­")
            
            # ç–‘ã‚ã—ã„IPã®ç›£è¦–
            for ip, count in self.suspicious_ips.items():
                if count > 10 and ip not in self.blocked_ips:
                    self.blocked_ips.add(ip)
                    await self._create_security_alert(
                        "ip_blocked",
                        ErrorSeverity.HIGH,
                        ip,
                        "/security",
                        f"IPã‚¢ãƒ‰ãƒ¬ã‚¹ {ip} ã‚’è‡ªå‹•ãƒ–ãƒ­ãƒƒã‚¯ã—ã¾ã—ãŸï¼ˆç–‘ã‚ã—ã„æ´»å‹•: {count}å›ï¼‰"
                    )
            
            logger.info("ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–é©ç”¨å®Œäº†")
            
        except Exception as e:
            logger.error(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _detect_suspicious_patterns(self):
        """ç•°å¸¸ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œçŸ¥"""
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç•°å¸¸ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œçŸ¥
        audit_log = self.log_paths.get("audit")
        if audit_log and audit_log.exists():
            try:
                async with aiofiles.open(audit_log, 'r') as f:
                    lines = await f.readlines()
                    recent_lines = lines[-1000:]  # æœ€æ–°1000è¡Œã‚’è§£æ
                    
                    for line in recent_lines:
                        await self._analyze_security_log_line(line)
                        
            except Exception as e:
                logger.error(f"ç–‘ã‚ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _detect_brute_force_attacks(self):
        """ãƒ–ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ã‚¹æ”»æ’ƒã®æ¤œçŸ¥"""
        # çŸ­æ™‚é–“ã§ã®èªè¨¼å¤±æ•—ã‚’ç›£è¦–
        recent_errors = [e for e in self.errors if 
                        e.timestamp > datetime.now() - timedelta(minutes=5) and
                        e.category == ErrorCategory.AUTH]
        
        if len(recent_errors) > 5:
            await self._create_security_alert(
                "brute_force_detected",
                ErrorSeverity.HIGH,
                "multiple",
                "/auth",
                f"5åˆ†é–“ã§{len(recent_errors)}ä»¶ã®èªè¨¼ã‚¨ãƒ©ãƒ¼ã‚’æ¤œçŸ¥"
            )
    
    async def _detect_injection_attempts(self):
        """SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è©¦è¡Œã®æ¤œçŸ¥"""
        # ãƒ­ã‚°ã‹ã‚‰SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œçŸ¥
        for error in self.errors:
            if any(re.search(pattern, error.message.lower()) for pattern_list in self.security_patterns["sql_injection"] for pattern in [pattern_list]):
                await self._create_security_alert(
                    "sql_injection_attempt",
                    ErrorSeverity.CRITICAL,
                    error.ip_address or "unknown",
                    error.endpoint,
                    f"SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒã‚’æ¤œçŸ¥: {error.message}"
                )
    
    async def _detect_xss_attempts(self):
        """XSSæ”»æ’ƒã®æ¤œçŸ¥"""
        # XSSãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œçŸ¥
        for error in self.errors:
            if any(re.search(pattern, error.message.lower()) for pattern_list in self.security_patterns["xss_attack"] for pattern in [pattern_list]):
                await self._create_security_alert(
                    "xss_attempt",
                    ErrorSeverity.HIGH,
                    error.ip_address or "unknown",
                    error.endpoint,
                    f"XSSæ”»æ’ƒã‚’æ¤œçŸ¥: {error.message}"
                )
    
    async def _create_security_alert(self, alert_type: str, severity: ErrorSeverity, source_ip: str, endpoint: str, description: str):
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ©ãƒ¼ãƒˆã®ä½œæˆ"""
        alert = SecurityAlert(
            timestamp=datetime.now(),
            alert_type=alert_type,
            severity=severity,
            source_ip=source_ip,
            target_endpoint=endpoint,
            description=description,
            blocked=source_ip in self.blocked_ips
        )
        
        self.security_alerts.append(alert)
        
        # ç–‘ã‚ã—ã„IPã‚«ã‚¦ãƒ³ã‚¿ãƒ¼æ›´æ–°
        if source_ip != "unknown" and source_ip != "system":
            self.suspicious_ips[source_ip] = self.suspicious_ips.get(source_ip, 0) + 1
        
        logger.warning(f"ğŸš¨ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ©ãƒ¼ãƒˆ: {alert_type} - {description}")
    
    async def _create_performance_alert(self, endpoint: str, value: float, alert_type: str):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¢ãƒ©ãƒ¼ãƒˆã®ä½œæˆ"""
        description = f"{endpoint}ã§{alert_type}: {value}"
        severity = ErrorSeverity.HIGH if value > 90 else ErrorSeverity.MEDIUM
        
        error = ApiError(
            timestamp=datetime.now(),
            error_type=alert_type,
            category=ErrorCategory.PERFORMANCE,
            severity=severity,
            message=description,
            stack_trace="",
            endpoint=endpoint,
            status_code=None,
            response_time=value if "response" in alert_type else None,
            user_agent=None,
            ip_address=None
        )
        
        self.errors.append(error)
    
    async def _create_documentation_error(self, endpoint: str, status_code: int, error_msg: str = ""):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼ã®ä½œæˆ"""
        error = ApiError(
            timestamp=datetime.now(),
            error_type="documentation_error",
            category=ErrorCategory.DOCUMENTATION,
            severity=ErrorSeverity.MEDIUM,
            message=f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {endpoint} (status: {status_code}) {error_msg}",
            stack_trace="",
            endpoint=endpoint,
            status_code=status_code,
            response_time=None,
            user_agent=None,
            ip_address=None
        )
        
        self.errors.append(error)
    
    async def _create_database_error(self, health_result: DatabaseHealthResult):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®ä½œæˆ"""
        if health_result.integrity_status != "ok":
            error = ApiError(
                timestamp=datetime.now(),
                error_type="database_integrity_error",
                category=ErrorCategory.DATABASE,
                severity=ErrorSeverity.CRITICAL,
                message=f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼: {health_result.integrity_status}",
                stack_trace="",
                endpoint="/database",
                status_code=None,
                response_time=None,
                user_agent=None,
                ip_address=None
            )
            self.errors.append(error)
        
        if health_result.size_mb > 1000:
            error = ApiError(
                timestamp=datetime.now(),
                error_type="database_size_warning",
                category=ErrorCategory.DATABASE,
                severity=ErrorSeverity.MEDIUM,
                message=f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™: {health_result.size_mb:.2f}MB",
                stack_trace="",
                endpoint="/database",
                status_code=None,
                response_time=None,
                user_agent=None,
                ip_address=None
            )
            self.errors.append(error)
    
    async def _analyze_security_log_line(self, line: str):
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¡Œã®è§£æ"""
        line_lower = line.lower()
        
        # IPã‚¢ãƒ‰ãƒ¬ã‚¹æŠ½å‡º
        ip_match = re.search(r'(\d+\.\d+\.\d+\.\d+)', line)
        source_ip = ip_match.group(1) if ip_match else "unknown"
        
        # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæŠ½å‡º
        endpoint_match = re.search(r'(GET|POST|PUT|DELETE|PATCH)\s+([^\s]+)', line)
        endpoint = endpoint_match.group(2) if endpoint_match else "unknown"
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒã‚§ãƒƒã‚¯
        for attack_type, patterns in self.security_patterns.items():
            for pattern in patterns:
                if re.search(pattern, line_lower):
                    await self._create_security_alert(
                        attack_type,
                        ErrorSeverity.HIGH,
                        source_ip,
                        endpoint,
                        f"{attack_type}ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œçŸ¥: {line.strip()}"
                    )
                    break
    
    async def update_comprehensive_metrics(self):
        """åŒ…æ‹¬çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ›´æ–°"""
        try:
            metrics = {
                "timestamp": datetime.now().isoformat(),
                "monitoring_status": {
                    "is_monitoring": self.monitoring,
                    "uptime_hours": (datetime.now() - datetime.now()).total_seconds() / 3600,
                },
                "error_metrics": {
                    "total_errors": len(self.errors),
                    "error_categories": {},
                    "error_severities": {},
                    "fix_success_rate": 0
                },
                "security_metrics": {
                    "total_alerts": len(self.security_alerts),
                    "blocked_ips": len(self.blocked_ips),
                    "suspicious_ips": len(self.suspicious_ips),
                    "alert_types": {}
                },
                "performance_metrics": {
                    "avg_response_time": 0,
                    "max_response_time": 0,
                    "current_cpu_usage": psutil.cpu_percent(),
                    "current_memory_usage": psutil.virtual_memory().percent
                },
                "database_health": {
                    "is_healthy": True,
                    "size_mb": 0,
                    "integrity_status": "unknown"
                },
                "health_status": "unknown"
            }
            
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†è¨ˆ
            for error in self.errors:
                cat = error.category.value
                metrics["error_metrics"]["error_categories"][cat] = metrics["error_metrics"]["error_categories"].get(cat, 0) + 1
                
                sev = error.severity.value
                metrics["error_metrics"]["error_severities"][sev] = metrics["error_metrics"]["error_severities"].get(sev, 0) + 1
            
            # ä¿®å¾©æˆåŠŸç‡
            attempted_fixes = [e for e in self.errors if e.fix_attempted]
            if attempted_fixes:
                successful_fixes = [e for e in attempted_fixes if e.fix_successful]
                metrics["error_metrics"]["fix_success_rate"] = len(successful_fixes) / len(attempted_fixes) * 100
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            for alert in self.security_alerts:
                alert_type = alert.alert_type
                metrics["security_metrics"]["alert_types"][alert_type] = metrics["security_metrics"]["alert_types"].get(alert_type, 0) + 1
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            if self.performance_metrics:
                response_times = [m.response_time for m in self.performance_metrics]
                metrics["performance_metrics"]["avg_response_time"] = sum(response_times) / len(response_times)
                metrics["performance_metrics"]["max_response_time"] = max(response_times)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹
            if self.database_health_history:
                latest_db_health = self.database_health_history[-1]
                metrics["database_health"] = {
                    "is_healthy": latest_db_health.is_healthy,
                    "size_mb": latest_db_health.size_mb,
                    "integrity_status": latest_db_health.integrity_status
                }
            
            # å…¨ä½“ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹
            if self.health_history:
                latest_health = self.health_history[-1]
                metrics["health_status"] = "healthy" if latest_health.is_healthy else "unhealthy"
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            metrics_path = self.backend_path / "comprehensive_api_metrics.json"
            async with aiofiles.open(metrics_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(metrics, indent=2, ensure_ascii=False))
                
            logger.info("ğŸ“Š åŒ…æ‹¬çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°å®Œäº†")
                
        except Exception as e:
            logger.error(f"åŒ…æ‹¬çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def generate_comprehensive_report(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=24)
            recent_errors = [e for e in self.errors if e.timestamp > cutoff_time]
            recent_alerts = [a for a in self.security_alerts if a.timestamp > cutoff_time]
            
            report = {
                "generated_at": datetime.now().isoformat(),
                "analysis_period": "24 hours",
                "executive_summary": {
                    "overall_health": "healthy",
                    "critical_issues": 0,
                    "security_threats": 0,
                    "performance_issues": 0,
                    "recommendations_count": 0
                },
                "error_analysis": {
                    "total_errors": len(recent_errors),
                    "critical_errors": len([e for e in recent_errors if e.severity == ErrorSeverity.CRITICAL]),
                    "fixed_errors": len([e for e in recent_errors if e.fix_successful]),
                    "error_breakdown": {}
                },
                "security_analysis": {
                    "total_alerts": len(recent_alerts),
                    "blocked_ips": len(self.blocked_ips),
                    "attack_types": {},
                    "threat_level": "low"
                },
                "performance_analysis": {
                    "avg_response_time": 0,
                    "slow_endpoints": [],
                    "resource_usage": {
                        "cpu": psutil.cpu_percent(),
                        "memory": psutil.virtual_memory().percent
                    }
                },
                "database_analysis": {
                    "health_status": "unknown",
                    "size_mb": 0,
                    "performance_issues": []
                },
                "recommendations": [],
                "action_items": []
            }
            
            # ã‚¨ãƒ©ãƒ¼åˆ†æ
            for error in recent_errors:
                cat = error.category.value
                if cat not in report["error_analysis"]["error_breakdown"]:
                    report["error_analysis"]["error_breakdown"][cat] = []
                
                report["error_analysis"]["error_breakdown"][cat].append({
                    "timestamp": error.timestamp.isoformat(),
                    "type": error.error_type,
                    "severity": error.severity.value,
                    "endpoint": error.endpoint,
                    "fixed": error.fix_successful
                })
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†æ
            for alert in recent_alerts:
                attack_type = alert.alert_type
                report["security_analysis"]["attack_types"][attack_type] = \
                    report["security_analysis"]["attack_types"].get(attack_type, 0) + 1
            
            # è„…å¨ãƒ¬ãƒ™ãƒ«åˆ¤å®š
            if len([a for a in recent_alerts if a.severity == ErrorSeverity.CRITICAL]) > 0:
                report["security_analysis"]["threat_level"] = "critical"
            elif len([a for a in recent_alerts if a.severity == ErrorSeverity.HIGH]) > 3:
                report["security_analysis"]["threat_level"] = "high"
            elif len(recent_alerts) > 10:
                report["security_analysis"]["threat_level"] = "medium"
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            if self.performance_metrics:
                recent_perf = [m for m in self.performance_metrics if m.timestamp > cutoff_time]
                if recent_perf:
                    response_times = [m.response_time for m in recent_perf]
                    report["performance_analysis"]["avg_response_time"] = sum(response_times) / len(response_times)
                    
                    # é…ã„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
                    slow_endpoints = [m for m in recent_perf if m.response_time > self.performance_thresholds["max_response_time"]]
                    report["performance_analysis"]["slow_endpoints"] = [
                        {"endpoint": m.endpoint, "response_time": m.response_time} for m in slow_endpoints
                    ]
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æ
            if self.database_health_history:
                latest_db = self.database_health_history[-1]
                report["database_analysis"]["health_status"] = "healthy" if latest_db.is_healthy else "unhealthy"
                report["database_analysis"]["size_mb"] = latest_db.size_mb
                
                if not latest_db.is_healthy:
                    report["database_analysis"]["performance_issues"].append(
                        f"æ•´åˆæ€§å•é¡Œ: {latest_db.integrity_status}"
                    )
            
            # æ¨å¥¨äº‹é …ç”Ÿæˆ
            if report["error_analysis"]["critical_errors"] > 0:
                report["recommendations"].append("ğŸš¨ ç·Šæ€¥: ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¨ãƒ©ãƒ¼ã®å³åº§ãªå¯¾å¿œãŒå¿…è¦")
                report["action_items"].append("ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¨ãƒ©ãƒ¼ã®æ ¹æœ¬åŸå› åˆ†æã¨ä¿®å¾©")
            
            if report["security_analysis"]["threat_level"] in ["high", "critical"]:
                report["recommendations"].append("ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: é«˜ãƒ¬ãƒ™ãƒ«ã®è„…å¨ã‚’æ¤œçŸ¥ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ãŒå¿…è¦")
                report["action_items"].append("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã®è¦‹ç›´ã—ã¨ãƒ‘ãƒƒãƒé©ç”¨")
            
            if len(report["performance_analysis"]["slow_endpoints"]) > 5:
                report["recommendations"].append("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: è¤‡æ•°ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ€§èƒ½åŠ£åŒ–")
                report["action_items"].append("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–")
            
            if report["database_analysis"]["health_status"] == "unhealthy":
                report["recommendations"].append("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•—ã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãŒå¿…è¦")
                report["action_items"].append("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã¨æœ€é©åŒ–")
            
            # å…¨ä½“çš„ãªå¥å…¨æ€§åˆ¤å®š
            critical_count = report["error_analysis"]["critical_errors"]
            security_threats = len(recent_alerts)
            performance_issues = len(report["performance_analysis"]["slow_endpoints"])
            
            if critical_count > 5 or report["security_analysis"]["threat_level"] == "critical":
                report["executive_summary"]["overall_health"] = "critical"
            elif critical_count > 0 or security_threats > 10 or performance_issues > 10:
                report["executive_summary"]["overall_health"] = "warning"
            else:
                report["executive_summary"]["overall_health"] = "healthy"
            
            report["executive_summary"]["critical_issues"] = critical_count
            report["executive_summary"]["security_threats"] = security_threats
            report["executive_summary"]["performance_issues"] = performance_issues
            report["executive_summary"]["recommendations_count"] = len(report["recommendations"])
            
            # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            report_path = self.backend_path / "comprehensive_api_report.json"
            async with aiofiles.open(report_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(report, indent=2, ensure_ascii=False))
            
            logger.info(f"ğŸ“‹ åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {report_path}")
            return report
            
        except Exception as e:
            logger.error(f"åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def get_status(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ç›£è¦–çŠ¶æ³ã‚’å–å¾—"""
        return {
            "monitoring": self.monitoring,
            "total_errors": len(self.errors),
            "recent_errors": len([e for e in self.errors if e.timestamp > datetime.now() - timedelta(hours=1)]),
            "security_alerts": len(self.security_alerts),
            "blocked_ips": len(self.blocked_ips),
            "database_health": self.database_health_history[-1].is_healthy if self.database_health_history else None,
            "last_health_check": self.health_history[-1].timestamp.isoformat() if self.health_history else None,
            "is_healthy": self.health_history[-1].is_healthy if self.health_history else None
        }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
api_monitor = ApiErrorMonitor()

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        logger.info("ğŸš€ APIã‚¨ãƒ©ãƒ¼ç›£è¦–ãƒ»ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã™")
        await api_monitor.start_monitoring(interval=30)
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç›£è¦–ã‚’åœæ­¢ã—ã¾ã™")
        api_monitor.stop_monitoring()
    except Exception as e:
        logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    
    asyncio.run(main())