#!/usr/bin/env python3
"""
Consolidated test report generator for ITSM system
Generates HTML and Markdown reports from test results
"""
import argparse
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import sys


class TestReportGenerator:
    """Generate consolidated test reports"""
    
    def __init__(self, input_dir: str, output_dir: str):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def collect_report_data(self) -> Dict[str, Any]:
        """Collect all test data from report files"""
        report_data = {
            "generated_at": datetime.now().isoformat(),
            "summary": {
                "total_tests": 0,
                "passed_tests": 0,
                "failed_tests": 0,
                "skipped_tests": 0,
                "success_rate": 0.0,
                "total_duration": 0.0
            },
            "suites": {},
            "performance": {},
            "coverage": {}
        }
        
        # Collect pytest JSON reports
        for json_file in self.input_dir.glob("*-report.json"):
            try:
                with open(json_file, 'r') as f:
                    data = json.load(f)
                    suite_name = json_file.stem.replace('-report', '')
                    report_data["suites"][suite_name] = self._process_pytest_report(data)
            except (json.JSONDecodeError, FileNotFoundError) as e:
                print(f"Warning: Could not process {json_file}: {e}")
        
        # Collect benchmark data
        benchmark_files = list(self.input_dir.glob("*benchmark*.json"))
        if benchmark_files:
            try:
                with open(benchmark_files[0], 'r') as f:
                    benchmark_data = json.load(f)
                    report_data["performance"]["benchmarks"] = self._process_benchmark_data(benchmark_data)
            except Exception as e:
                print(f"Warning: Could not process benchmark data: {e}")
        
        # Collect coverage data
        coverage_files = list(self.input_dir.glob("coverage*.json"))
        if coverage_files:
            try:
                with open(coverage_files[0], 'r') as f:
                    coverage_data = json.load(f)
                    report_data["coverage"] = self._process_coverage_data(coverage_data)
            except Exception as e:
                print(f"Warning: Could not process coverage data: {e}")
        
        # Calculate summary
        report_data["summary"] = self._calculate_summary(report_data["suites"])
        
        return report_data
    
    def _process_pytest_report(self, data: Dict) -> Dict[str, Any]:
        """Process pytest JSON report data"""
        if isinstance(data, dict) and "summary" in data:
            summary = data["summary"]
            return {
                "total": summary.get("total", 0),
                "passed": summary.get("passed", 0),
                "failed": summary.get("failed", 0),
                "skipped": summary.get("skipped", 0),
                "duration": data.get("duration", 0),
                "success_rate": (summary.get("passed", 0) / max(summary.get("total", 1), 1)) * 100
            }
        else:
            # Handle other pytest report formats
            return {
                "total": 0,
                "passed": 0,
                "failed": 0,
                "skipped": 0,
                "duration": 0,
                "success_rate": 0
            }
    
    def _process_benchmark_data(self, data: Dict) -> Dict[str, Any]:
        """Process benchmark data"""
        benchmarks = []
        
        if "benchmarks" in data:
            for bench in data["benchmarks"]:
                benchmarks.append({
                    "name": bench.get("name", ""),
                    "min": bench.get("stats", {}).get("min", 0),
                    "max": bench.get("stats", {}).get("max", 0),
                    "mean": bench.get("stats", {}).get("mean", 0),
                    "median": bench.get("stats", {}).get("median", 0),
                    "ops": bench.get("stats", {}).get("ops", 0),
                    "rounds": bench.get("stats", {}).get("rounds", 0)
                })
        
        return {
            "total_benchmarks": len(benchmarks),
            "benchmarks": benchmarks
        }
    
    def _process_coverage_data(self, data: Dict) -> Dict[str, Any]:
        """Process coverage data"""
        return {
            "percent_covered": data.get("totals", {}).get("percent_covered", 0),
            "num_statements": data.get("totals", {}).get("num_statements", 0),
            "missing_lines": data.get("totals", {}).get("missing_lines", 0),
            "covered_lines": data.get("totals", {}).get("covered_lines", 0)
        }
    
    def _calculate_summary(self, suites: Dict) -> Dict[str, Any]:
        """Calculate overall summary from all test suites"""
        total_tests = sum(suite.get("total", 0) for suite in suites.values())
        passed_tests = sum(suite.get("passed", 0) for suite in suites.values())
        failed_tests = sum(suite.get("failed", 0) for suite in suites.values())
        skipped_tests = sum(suite.get("skipped", 0) for suite in suites.values())
        total_duration = sum(suite.get("duration", 0) for suite in suites.values())
        
        success_rate = (passed_tests / max(total_tests, 1)) * 100
        
        return {
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "failed_tests": failed_tests,
            "skipped_tests": skipped_tests,
            "success_rate": round(success_rate, 2),
            "total_duration": round(total_duration, 2)
        }
    
    def generate_html_report(self, data: Dict[str, Any]) -> str:
        """Generate HTML report"""
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ITSM ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .header {{ text-align: center; margin-bottom: 30px; color: #333; }}
        .summary {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }}
        .metric {{ background: #f8f9fa; padding: 20px; border-radius: 8px; text-align: center; border-left: 4px solid #007bff; }}
        .metric.success {{ border-left-color: #28a745; }}
        .metric.warning {{ border-left-color: #ffc107; }}
        .metric.danger {{ border-left-color: #dc3545; }}
        .metric-value {{ font-size: 2em; font-weight: bold; color: #333; }}
        .metric-label {{ color: #666; margin-top: 5px; }}
        .section {{ margin-bottom: 30px; }}
        .section h3 {{ color: #333; border-bottom: 2px solid #007bff; padding-bottom: 10px; }}
        table {{ width: 100%; border-collapse: collapse; margin-top: 10px; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background-color: #f8f9fa; font-weight: bold; }}
        .status-passed {{ color: #28a745; font-weight: bold; }}
        .status-failed {{ color: #dc3545; font-weight: bold; }}
        .progress-bar {{ width: 100%; height: 20px; background-color: #e9ecef; border-radius: 10px; overflow: hidden; }}
        .progress-fill {{ height: 100%; background-color: #28a745; transition: width 0.3s ease; }}
        .timestamp {{ color: #666; font-size: 0.9em; text-align: center; margin-top: 20px; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ§ª ITSM ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ</h1>
            <p>åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ</p>
        </div>
        
        <div class="summary">
            <div class="metric {'success' if data['summary']['success_rate'] >= 95 else 'warning' if data['summary']['success_rate'] >= 80 else 'danger'}">
                <div class="metric-value">{data['summary']['success_rate']:.1f}%</div>
                <div class="metric-label">æˆåŠŸç‡</div>
            </div>
            <div class="metric">
                <div class="metric-value">{data['summary']['total_tests']}</div>
                <div class="metric-label">ç·ãƒ†ã‚¹ãƒˆæ•°</div>
            </div>
            <div class="metric success">
                <div class="metric-value">{data['summary']['passed_tests']}</div>
                <div class="metric-label">æˆåŠŸãƒ†ã‚¹ãƒˆ</div>
            </div>
            <div class="metric {'danger' if data['summary']['failed_tests'] > 0 else ''}">
                <div class="metric-value">{data['summary']['failed_tests']}</div>
                <div class="metric-label">å¤±æ•—ãƒ†ã‚¹ãƒˆ</div>
            </div>
            <div class="metric">
                <div class="metric-value">{data['summary']['total_duration']:.1f}s</div>
                <div class="metric-label">å®Ÿè¡Œæ™‚é–“</div>
            </div>
        </div>

        <div class="section">
            <h3>ğŸ“Š ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆåˆ¥çµæœ</h3>
            <table>
                <thead>
                    <tr>
                        <th>ã‚¹ã‚¤ãƒ¼ãƒˆå</th>
                        <th>ç·æ•°</th>
                        <th>æˆåŠŸ</th>
                        <th>å¤±æ•—</th>
                        <th>ã‚¹ã‚­ãƒƒãƒ—</th>
                        <th>æˆåŠŸç‡</th>
                        <th>å®Ÿè¡Œæ™‚é–“</th>
                    </tr>
                </thead>
                <tbody>"""
        
        for suite_name, suite_data in data["suites"].items():
            success_rate = suite_data.get("success_rate", 0)
            status_class = "status-passed" if success_rate >= 95 else "status-failed" if success_rate < 80 else ""
            
            html_content += f"""
                    <tr>
                        <td><strong>{suite_name}</strong></td>
                        <td>{suite_data.get('total', 0)}</td>
                        <td class="status-passed">{suite_data.get('passed', 0)}</td>
                        <td class="{'status-failed' if suite_data.get('failed', 0) > 0 else ''}">{suite_data.get('failed', 0)}</td>
                        <td>{suite_data.get('skipped', 0)}</td>
                        <td class="{status_class}">{success_rate:.1f}%</td>
                        <td>{suite_data.get('duration', 0):.2f}s</td>
                    </tr>"""
        
        html_content += """
                </tbody>
            </table>
        </div>"""
        
        # Performance section
        if "benchmarks" in data.get("performance", {}):
            html_content += """
        <div class="section">
            <h3>âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</h3>
            <table>
                <thead>
                    <tr>
                        <th>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å</th>
                        <th>å¹³å‡æ™‚é–“</th>
                        <th>æœ€å°æ™‚é–“</th>
                        <th>æœ€å¤§æ™‚é–“</th>
                        <th>OPS</th>
                        <th>ãƒ©ã‚¦ãƒ³ãƒ‰æ•°</th>
                    </tr>
                </thead>
                <tbody>"""
            
            for bench in data["performance"]["benchmarks"]["benchmarks"]:
                html_content += f"""
                    <tr>
                        <td>{bench['name']}</td>
                        <td>{bench['mean']:.6f}s</td>
                        <td>{bench['min']:.6f}s</td>
                        <td>{bench['max']:.6f}s</td>
                        <td>{bench['ops']:.2f}</td>
                        <td>{bench['rounds']}</td>
                    </tr>"""
            
            html_content += """
                </tbody>
            </table>
        </div>"""
        
        # Coverage section
        if data.get("coverage"):
            coverage_percent = data["coverage"].get("percent_covered", 0)
            html_content += f"""
        <div class="section">
            <h3>ğŸ“ˆ ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸</h3>
            <div style="margin-bottom: 15px;">
                <div style="display: flex; justify-content: space-between; margin-bottom: 5px;">
                    <span>ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡</span>
                    <span><strong>{coverage_percent:.1f}%</strong></span>
                </div>
                <div class="progress-bar">
                    <div class="progress-fill" style="width: {coverage_percent}%;"></div>
                </div>
            </div>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 10px;">
                <div>ç·ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆæ•°: <strong>{data['coverage'].get('num_statements', 0)}</strong></div>
                <div>ã‚«ãƒãƒ¼æ¸ˆã¿è¡Œæ•°: <strong>{data['coverage'].get('covered_lines', 0)}</strong></div>
                <div>æœªã‚«ãƒãƒ¼è¡Œæ•°: <strong>{data['coverage'].get('missing_lines', 0)}</strong></div>
            </div>
        </div>"""
        
        html_content += f"""
        <div class="timestamp">
            ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ—¥æ™‚: {data['generated_at']}
        </div>
    </div>
</body>
</html>"""
        
        return html_content
    
    def generate_markdown_report(self, data: Dict[str, Any]) -> str:
        """Generate Markdown report"""
        md_content = f"""# ğŸ§ª ITSM ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥æ™‚:** {data['generated_at']}

## ğŸ“Š å®Ÿè¡Œã‚µãƒãƒªãƒ¼

| é …ç›® | å€¤ |
|------|-----|
| **ç·ãƒ†ã‚¹ãƒˆæ•°** | {data['summary']['total_tests']} |
| **æˆåŠŸãƒ†ã‚¹ãƒˆ** | {data['summary']['passed_tests']} |
| **å¤±æ•—ãƒ†ã‚¹ãƒˆ** | {data['summary']['failed_tests']} |
| **ã‚¹ã‚­ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ** | {data['summary']['skipped_tests']} |
| **æˆåŠŸç‡** | {data['summary']['success_rate']:.2f}% |
| **ç·å®Ÿè¡Œæ™‚é–“** | {data['summary']['total_duration']:.2f}ç§’ |

## ğŸ¯ å“è³ªã‚²ãƒ¼ãƒˆåˆ¤å®š

"""
        
        # Quality gate assessment
        success_rate = data['summary']['success_rate']
        if success_rate >= 95:
            md_content += "âœ… **PASS** - å…¨ã¦ã®å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™\n\n"
        elif success_rate >= 80:
            md_content += "âš ï¸ **WARNING** - ä¸€éƒ¨å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“\n\n"
        else:
            md_content += "âŒ **FAIL** - å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚ãƒªãƒªãƒ¼ã‚¹ä¸å¯\n\n"
        
        # Test suites
        md_content += "## ğŸ“‹ ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆåˆ¥çµæœ\n\n"
        md_content += "| ã‚¹ã‚¤ãƒ¼ãƒˆ | ç·æ•° | æˆåŠŸ | å¤±æ•— | ã‚¹ã‚­ãƒƒãƒ— | æˆåŠŸç‡ | å®Ÿè¡Œæ™‚é–“ |\n"
        md_content += "|----------|------|------|------|----------|---------|----------|\n"
        
        for suite_name, suite_data in data["suites"].items():
            success_icon = "âœ…" if suite_data.get("success_rate", 0) >= 95 else "âš ï¸" if suite_data.get("success_rate", 0) >= 80 else "âŒ"
            md_content += f"| {success_icon} {suite_name} | {suite_data.get('total', 0)} | {suite_data.get('passed', 0)} | {suite_data.get('failed', 0)} | {suite_data.get('skipped', 0)} | {suite_data.get('success_rate', 0):.1f}% | {suite_data.get('duration', 0):.2f}s |\n"
        
        # Performance benchmarks
        if "benchmarks" in data.get("performance", {}):
            md_content += "\n## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯\n\n"
            md_content += "| ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å | å¹³å‡æ™‚é–“ | æœ€å°æ™‚é–“ | æœ€å¤§æ™‚é–“ | OPS | ãƒ©ã‚¦ãƒ³ãƒ‰æ•° |\n"
            md_content += "|----------------|-----------|-----------|-----------|-----|------------|\n"
            
            for bench in data["performance"]["benchmarks"]["benchmarks"]:
                md_content += f"| {bench['name']} | {bench['mean']:.6f}s | {bench['min']:.6f}s | {bench['max']:.6f}s | {bench['ops']:.2f} | {bench['rounds']} |\n"
        
        # Coverage
        if data.get("coverage"):
            coverage = data["coverage"]
            md_content += f"\n## ğŸ“ˆ ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸\n\n"
            md_content += f"- **ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡:** {coverage.get('percent_covered', 0):.1f}%\n"
            md_content += f"- **ç·ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆæ•°:** {coverage.get('num_statements', 0)}\n"
            md_content += f"- **ã‚«ãƒãƒ¼æ¸ˆã¿è¡Œæ•°:** {coverage.get('covered_lines', 0)}\n"
            md_content += f"- **æœªã‚«ãƒãƒ¼è¡Œæ•°:** {coverage.get('missing_lines', 0)}\n"
        
        md_content += "\n---\n\n*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚*\n"
        
        return md_content
    
    def generate_json_summary(self, data: Dict[str, Any]) -> str:
        """Generate JSON summary for manager"""
        summary = {
            "test_execution_summary": {
                "generated_at": data["generated_at"],
                "overall_status": "PASS" if data["summary"]["success_rate"] >= 95 else "FAIL",
                "quality_gate_result": {
                    "passed": data["summary"]["success_rate"] >= 95,
                    "success_rate": data["summary"]["success_rate"],
                    "threshold": 95.0
                },
                "metrics": data["summary"],
                "suite_results": data["suites"],
                "recommendations": self._generate_recommendations(data)
            }
        }
        
        return json.dumps(summary, indent=2, ensure_ascii=False)
    
    def _generate_recommendations(self, data: Dict[str, Any]) -> List[str]:
        """Generate comprehensive recommendations based on test results"""
        recommendations = []
        
        success_rate = data["summary"]["success_rate"]
        total_duration = data["summary"]["total_duration"]
        
        # Test success rate recommendations
        if success_rate < 95:
            if success_rate < 50:
                recommendations.append("ğŸš¨ CRITICAL: ãƒ†ã‚¹ãƒˆæˆåŠŸç‡ãŒ50%ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™ã€‚å³åº§ã«ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
            elif success_rate < 80:
                recommendations.append("âš ï¸ ãƒ†ã‚¹ãƒˆæˆåŠŸç‡ãŒ80%ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™ã€‚å“è³ªã‚²ãƒ¼ãƒˆä¸åˆæ ¼ã§ã™ã€‚")
            else:
                recommendations.append("ğŸ“ˆ ãƒ†ã‚¹ãƒˆæˆåŠŸç‡ãŒ95%ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™ã€‚å®‰å®šæ€§å‘ä¸Šã®ãŸã‚ä¿®æ­£æ¨å¥¨ã§ã™ã€‚")
        
        # Failed tests
        failed_count = data["summary"]["failed_tests"]
        if failed_count > 0:
            if failed_count > 10:
                recommendations.append(f"ğŸ”¥ {failed_count}ä»¶ã®å¤§é‡ã®ãƒ†ã‚¹ãƒˆå¤±æ•—ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚å„ªå…ˆåº¦é«˜ã§å¯¾å¿œã—ã¦ãã ã•ã„ã€‚")
            else:
                recommendations.append(f"ğŸ› {failed_count}ä»¶ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¦ã„ã¾ã™ã€‚è©³ç´°ãªãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # Performance recommendations
        if total_duration > 300:  # 5 minutes
            recommendations.append("â° ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“ãŒ5åˆ†ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ãƒ†ã‚¹ãƒˆã®ä¸¦åˆ—åŒ–ã‚„æœ€é©åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
        elif total_duration > 600:  # 10 minutes
            recommendations.append("ğŸŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“ãŒ10åˆ†ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åŠ¹ç‡åŒ–ãŒå¿…è¦ã§ã™ã€‚")
        
        # Suite-specific recommendations
        critical_suites = ["api", "unit", "e2e"]
        for suite_name, suite_data in data["suites"].items():
            suite_success_rate = suite_data.get("success_rate", 0)
            suite_duration = suite_data.get("duration", 0)
            
            if suite_success_rate < 80:
                if suite_name in critical_suites:
                    recommendations.append(f"ğŸš« {suite_name}ã‚¹ã‚¤ãƒ¼ãƒˆï¼ˆã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ï¼‰ã®æˆåŠŸç‡ãŒ{suite_success_rate:.1f}%ã§ã™ã€‚å³åº§ã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
                else:
                    recommendations.append(f"âš ï¸ {suite_name}ã‚¹ã‚¤ãƒ¼ãƒˆã®æˆåŠŸç‡ãŒ{suite_success_rate:.1f}%ã§ã™ã€‚å„ªå…ˆçš„ã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
            
            # Suite performance
            if suite_name == "unit" and suite_duration > 60:
                recommendations.append(f"âš¡ ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œæ™‚é–“ãŒ{suite_duration:.1f}ç§’ã§ã™ã€‚1åˆ†ä»¥å†…ã‚’ç›®æ¨™ã«æœ€é©åŒ–ã—ã¦ãã ã•ã„ã€‚")
            elif suite_name == "e2e" and suite_duration > 300:
                recommendations.append(f"ğŸ­ E2Eãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œæ™‚é–“ãŒ{suite_duration:.1f}ç§’ã§ã™ã€‚ä¸¦åˆ—å®Ÿè¡Œã‚„é¸æŠçš„å®Ÿè¡Œã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
        
        # Coverage recommendations (if available)
        if data.get("coverage"):
            coverage_percent = data["coverage"].get("percent_covered", 0)
            if coverage_percent < 60:
                recommendations.append(f"ğŸ“Š ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ{coverage_percent:.1f}%ã§ã™ã€‚æœ€ä½60%ã‚’ç›®æ¨™ã«ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
            elif coverage_percent < 80:
                recommendations.append(f"ğŸ“ˆ ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ{coverage_percent:.1f}%ã§ã™ã€‚80%ã‚’ç›®æ¨™ã«ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’å‘ä¸Šã•ã›ã¦ãã ã•ã„ã€‚")
        
        # Performance benchmark recommendations
        if "benchmarks" in data.get("performance", {}):
            slow_benchmarks = []
            for bench in data["performance"]["benchmarks"]["benchmarks"]:
                if bench.get("mean", 0) > 1.0:  # Slower than 1 second
                    slow_benchmarks.append(f"{bench['name']} ({bench['mean']:.3f}s)")
            
            if slow_benchmarks:
                recommendations.append(f"ğŸŒ å®Ÿè¡Œæ™‚é–“ã®é•·ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯: {', '.join(slow_benchmarks[:3])}{'...' if len(slow_benchmarks) > 3 else ''}")
        
        # Overall health assessment
        if not recommendations:
            if success_rate == 100:
                recommendations.append("ğŸ‰ å®Œç’§ï¼å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã€å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™ã€‚")
            elif success_rate >= 98:
                recommendations.append("âœ¨ å„ªç§€ï¼é«˜å“è³ªã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚ç¾åœ¨ã®æ°´æº–ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚")
            else:
                recommendations.append("âœ… è‰¯å¥½ï¼å…¨ã¦ã®å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™ã€‚")
        
        # Add proactive suggestions
        if success_rate >= 95:
            recommendations.append("ğŸ’¡ ææ¡ˆ: ãƒ†ã‚¹ãƒˆè‡ªå‹•åŒ–ã®æ‹¡å¼µã‚„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®è¿½åŠ ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
        
        return recommendations
    
    def generate_reports(self):
        """Generate all report formats"""
        print("ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")
        data = self.collect_report_data()
        
        print("ğŸ“ HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
        html_report = self.generate_html_report(data)
        html_path = self.output_dir / "report.html"
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        print("ğŸ“‹ Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
        md_report = self.generate_markdown_report(data)
        md_path = self.output_dir / "report.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(md_report)
        
        print("ğŸ“Š JSONã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆä¸­...")
        json_summary = self.generate_json_summary(data)
        json_path = self.output_dir / "summary.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            f.write(json_summary)
        
        print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†:")
        print(f"   - HTML: {html_path}")
        print(f"   - Markdown: {md_path}")
        print(f"   - JSON: {json_path}")
        
        return {
            "html_path": str(html_path),
            "markdown_path": str(md_path),
            "json_path": str(json_path),
            "data": data
        }


def main():
    parser = argparse.ArgumentParser(description="Generate consolidated test reports")
    parser.add_argument("--input-dir", required=True, help="Directory containing test report files")
    parser.add_argument("--output-dir", required=True, help="Directory to save generated reports")
    
    args = parser.parse_args()
    
    try:
        generator = TestReportGenerator(args.input_dir, args.output_dir)
        results = generator.generate_reports()
        
        # Return success
        sys.exit(0)
        
    except Exception as e:
        print(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()