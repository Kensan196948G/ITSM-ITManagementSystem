#!/usr/bin/env python3
"""
GitHub Actions å¤±æ•—â†’Claudeè‡ªå‹•ä¿®å¾©â†’å†å®Ÿè¡Œãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ 
Enhanced Auto-Repair System with Claude Flow MCP Integration
"""

import asyncio
import json
import logging
import subprocess
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import re
import sys
import os
import hashlib
import tempfile
import yaml
import shutil
from dataclasses import dataclass, asdict
from enum import Enum

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

class RepairStatus(Enum):
    """ä¿®å¾©ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    REQUIRES_MANUAL = "requires_manual"

class SecurityLevel(Enum):
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ™ãƒ«"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4
    
    def __ge__(self, other):
        if isinstance(other, SecurityLevel):
            return self.value >= other.value
        return NotImplemented
    
    def __gt__(self, other):
        if isinstance(other, SecurityLevel):
            return self.value > other.value
        return NotImplemented
    
    def __le__(self, other):
        if isinstance(other, SecurityLevel):
            return self.value <= other.value
        return NotImplemented
    
    def __lt__(self, other):
        if isinstance(other, SecurityLevel):
            return self.value < other.value
        return NotImplemented

@dataclass
class RepairContext:
    """ä¿®å¾©ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
    run_id: str
    workflow_name: str
    commit_sha: str
    error_type: str
    error_logs: str
    created_at: str
    security_level: SecurityLevel
    auto_approve: bool
    repair_attempts: int = 0

@dataclass
class RepairResult:
    """ä¿®å¾©çµæœ"""
    success: bool
    branch_name: Optional[str] = None
    pr_url: Optional[str] = None
    changes_applied: List[Dict] = None
    error_message: Optional[str] = None
    confidence_score: float = 0.0
    security_impact: SecurityLevel = SecurityLevel.LOW

class EnhancedGitHubActionsAutoRepair:
    """æ‹¡å¼µGitHub Actionsè‡ªå‹•ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, repo_owner: str = "Kensan196948G", repo_name: str = "ITSM-ITManagementSystem"):
        self.repo_owner = repo_owner
        self.repo_name = repo_name
        self.base_path = Path(__file__).parent
        self.project_root = self.base_path.parent
        
        # ãƒ­ã‚°è¨­å®š
        self.setup_logging()
        
        # è¨­å®šèª­ã¿è¾¼ã¿
        self.config = self.load_config()
        
        # çŠ¶æ…‹ç®¡ç†
        self.state_file = self.base_path / "enhanced_repair_state.json"
        self.state = self.load_state()
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
        self.security_config = self.load_security_config()
        
        # Claude Flowçµ±åˆ
        self.claude_flow = ClaudeFlowIntegration(self.project_root, self.logger)
        
        # æ‰¿èªã‚·ã‚¹ãƒ†ãƒ 
        self.approval_system = ApprovalSystem(self.config, self.logger)
        
        # ç›£è¦–çµ±è¨ˆ
        self.metrics = RepairMetrics()
        
        self.logger.info(f"Enhanced GitHub Actions Auto-Repair System initialized")

    def setup_logging(self):
        """è©³ç´°ãƒ­ã‚°è¨­å®š"""
        log_file = self.base_path / "enhanced_github_actions_repair.log"
        
        # ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã®è¨­å®š
        from logging.handlers import RotatingFileHandler
        
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s'
        )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ï¼ˆ5MBã€3ä¸–ä»£ä¿æŒï¼‰
        file_handler = RotatingFileHandler(
            log_file, maxBytes=5*1024*1024, backupCount=3
        )
        file_handler.setFormatter(formatter)
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        
        # ãƒ­ã‚¬ãƒ¼è¨­å®š
        self.logger = logging.getLogger("EnhancedAutoRepair")
        self.logger.setLevel(logging.INFO)
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)

    def load_config(self) -> Dict:
        """è¨­å®šèª­ã¿è¾¼ã¿"""
        config_file = self.base_path / "enhanced_repair_config.json"
        
        default_config = {
            "monitoring": {
                "poll_interval": 30,
                "max_concurrent_repairs": 3,
                "retry_delay": 60,
                "health_check_interval": 300
            },
            "repair": {
                "max_repair_cycles": 15,
                "confidence_threshold": 0.75,
                "timeout_seconds": 600,
                "max_file_changes": 10
            },
            "security": {
                "manual_approval_threshold": SecurityLevel.MEDIUM.value,
                "isolation_branch_prefix": "claude-autofix",
                "require_review_for_critical": True,
                "backup_before_repair": True
            },
            "claude_flow": {
                "command": "npx claude-flow@alpha mcp start",
                "timeout": 300,
                "auto_mode": True,
                "max_tokens": 8192
            },
            "github": {
                "auto_merge_threshold": 0.9,
                "pr_template_path": ".github/pull_request_template.md",
                "required_checks": ["CI", "Tests"],
                "auto_assign_reviewers": True
            },
            "quality_gates": {
                "required_clean_cycles": 3,
                "test_pass_requirement": True,
                "lint_pass_requirement": True,
                "coverage_threshold": 0.8
            }
        }
        
        if config_file.exists():
            with open(config_file, 'r') as f:
                user_config = json.load(f)
                # ãƒ‡ã‚£ãƒ¼ãƒ—ãƒãƒ¼ã‚¸
                return self.deep_merge(default_config, user_config)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä¿å­˜
            with open(config_file, 'w') as f:
                json.dump(default_config, f, indent=2)
            return default_config

    def deep_merge(self, dict1: Dict, dict2: Dict) -> Dict:
        """è¾æ›¸ã®æ·±ã„ãƒãƒ¼ã‚¸"""
        result = dict1.copy()
        for key, value in dict2.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self.deep_merge(result[key], value)
            else:
                result[key] = value
        return result

    def load_security_config(self) -> Dict:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šèª­ã¿è¾¼ã¿"""
        return {
            "critical_files": [
                "backend/app/core/security.py",
                "backend/app/core/config.py",
                "backend/app/api/deps.py",
                ".github/workflows/",
                "docker-compose.yml",
                "requirements.txt",
                "package.json",
                ".env*"
            ],
            "sensitive_patterns": [
                r"password",
                r"secret",
                r"token",
                r"key",
                r"auth",
                r"credential"
            ],
            "auto_deny_patterns": [
                r"rm\s+-rf",
                r"sudo",
                r"chmod\s+777",
                r"--force"
            ]
        }

    def load_state(self) -> Dict:
        """çŠ¶æ…‹èª­ã¿è¾¼ã¿"""
        if self.state_file.exists():
            with open(self.state_file, 'r') as f:
                return json.load(f)
        else:
            return {
                "monitoring": False,
                "repair_cycles": 0,
                "consecutive_clean_cycles": 0,
                "last_check": None,
                "active_repairs": {},
                "repair_history": [],
                "metrics": {
                    "total_repairs": 0,
                    "successful_repairs": 0,
                    "failed_repairs": 0,
                    "manual_approvals": 0,
                    "auto_approvals": 0
                }
            }

    def save_state(self):
        """çŠ¶æ…‹ä¿å­˜"""
        self.state["last_updated"] = datetime.now().isoformat()
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        if self.state_file.exists():
            backup_file = self.state_file.with_suffix(f'.backup.{int(time.time())}.json')
            shutil.copy2(self.state_file, backup_file)
        
        with open(self.state_file, 'w') as f:
            json.dump(self.state, f, indent=2)

    async def enhanced_error_analysis(self, logs: str, run_info: Dict) -> Dict:
        """æ‹¡å¼µã‚¨ãƒ©ãƒ¼åˆ†æ"""
        analysis = {
            "error_types": [],
            "severity": SecurityLevel.LOW,
            "confidence": 0.0,
            "suggested_actions": [],
            "affected_files": [],
            "root_causes": []
        }
        
        # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        error_patterns = {
            "dependency": {
                "patterns": [
                    r"ModuleNotFoundError: No module named '([^']+)'",
                    r"ImportError: cannot import name '([^']+)'",
                    r"npm ERR! Cannot resolve dependency '([^']+)'",
                    r"Package '([^']+)' not found"
                ],
                "severity": SecurityLevel.MEDIUM,
                "actions": ["update_dependencies", "install_missing_packages"]
            },
            "syntax": {
                "patterns": [
                    r"SyntaxError: (.+)",
                    r"IndentationError: (.+)",
                    r"TypeError: (.+)"
                ],
                "severity": SecurityLevel.LOW,
                "actions": ["fix_syntax", "check_indentation"]
            },
            "test_failure": {
                "patterns": [
                    r"FAILED (.+) - (.+)",
                    r"AssertionError: (.+)",
                    r"Test (.+) failed"
                ],
                "severity": SecurityLevel.LOW,
                "actions": ["fix_test_logic", "update_test_data"]
            },
            "build": {
                "patterns": [
                    r"Build failed: (.+)",
                    r"compilation error: (.+)",
                    r"webpack.*Error: (.+)"
                ],
                "severity": SecurityLevel.MEDIUM,
                "actions": ["fix_build_config", "update_build_dependencies"]
            },
            "security": {
                "patterns": [
                    r"security vulnerability: (.+)",
                    r"CVE-\d{4}-\d+",
                    r"audit.*vulnerability"
                ],
                "severity": SecurityLevel.CRITICAL,
                "actions": ["security_patch", "vulnerability_fix"]
            }
        }
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ
        max_severity = SecurityLevel.LOW
        total_confidence = 0.0
        match_count = 0
        
        for error_type, config in error_patterns.items():
            for pattern in config["patterns"]:
                matches = re.finditer(pattern, logs, re.IGNORECASE | re.MULTILINE)
                for match in matches:
                    analysis["error_types"].append({
                        "type": error_type,
                        "match": match.group(0),
                        "location": match.span(),
                        "severity": config["severity"].value
                    })
                    
                    if config["severity"].value > max_severity.value:
                        max_severity = config["severity"]
                    
                    analysis["suggested_actions"].extend(config["actions"])
                    match_count += 1
                    total_confidence += 0.8  # åŸºæœ¬ä¿¡é ¼åº¦
        
        analysis["severity"] = max_severity
        analysis["confidence"] = min(total_confidence / max(match_count, 1), 1.0)
        
        # å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«æŠ½å‡º
        file_patterns = [
            r"File \"([^\"]+)\"",
            r"at ([^\s]+):\d+",
            r"in file ([^\s]+)"
        ]
        
        for pattern in file_patterns:
            files = re.findall(pattern, logs)
            analysis["affected_files"].extend(files)
        
        # é‡è¤‡é™¤å»
        analysis["affected_files"] = list(set(analysis["affected_files"]))
        analysis["suggested_actions"] = list(set(analysis["suggested_actions"]))
        
        return analysis

    async def create_repair_context(self, run_info: Dict, error_analysis: Dict) -> RepairContext:
        """ä¿®å¾©ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ"""
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ™ãƒ«æ±ºå®š
        security_level = SecurityLevel(error_analysis["severity"])
        
        # è‡ªå‹•æ‰¿èªåˆ¤å®š
        auto_approve = await self.approval_system.can_auto_approve(
            error_analysis, run_info
        )
        
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°å–å¾—
        error_logs = await self.extract_error_logs(str(run_info["id"]))
        
        return RepairContext(
            run_id=str(run_info["id"]),
            workflow_name=run_info.get("name", "Unknown"),
            commit_sha=run_info.get("head_sha", "Unknown"),
            error_type=",".join([e["type"] for e in error_analysis["error_types"]]),
            error_logs=error_logs,
            created_at=run_info.get("created_at", datetime.now().isoformat()),
            security_level=security_level,
            auto_approve=auto_approve
        )

    async def extract_error_logs(self, run_id: str) -> str:
        """å¼·åŒ–ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒ­ã‚°æŠ½å‡º"""
        try:
            # è¤‡æ•°ã®æ–¹æ³•ã§ãƒ­ã‚°ã‚’å–å¾—
            methods = [
                ["gh", "run", "view", run_id, "--log"],
                ["gh", "api", f"repos/{self.repo_owner}/{self.repo_name}/actions/runs/{run_id}/logs"]
            ]
            
            for method in methods:
                try:
                    result = subprocess.run(
                        method, 
                        capture_output=True, 
                        text=True, 
                        timeout=60
                    )
                    if result.returncode == 0 and result.stdout:
                        return result.stdout
                except Exception as e:
                    self.logger.debug(f"Log extraction method failed: {method} - {e}")
                    continue
            
            self.logger.warning(f"Failed to extract logs for run {run_id}")
            return ""
            
        except Exception as e:
            self.logger.error(f"Error extracting logs for run {run_id}: {e}")
            return ""

    async def generate_enhanced_claude_prompt(self, context: RepairContext, error_analysis: Dict) -> str:
        """æ‹¡å¼µClaudeä¿®å¾©ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ æƒ…å ±ã‚’å«ã‚ã‚‹
        project_structure = await self.get_project_structure()
        
        # é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å«ã‚ã‚‹
        relevant_files = await self.get_relevant_files(error_analysis["affected_files"])
        
        prompt = f"""# GitHub Actions è‡ªå‹•ä¿®å¾©ã‚¿ã‚¹ã‚¯ (Enhanced)

## ğŸš¨ å®Ÿè¡Œæƒ…å ±
- **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: {context.workflow_name}
- **å®Ÿè¡ŒID**: {context.run_id}
- **ã‚³ãƒŸãƒƒãƒˆ**: {context.commit_sha}
- **å¤±æ•—æ™‚åˆ»**: {context.created_at}
- **ä¿®å¾©æ™‚åˆ»**: {timestamp}
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ™ãƒ«**: {context.security_level.value}
- **è‡ªå‹•æ‰¿èª**: {'å¯èƒ½' if context.auto_approve else 'ä¸å¯'}

## ğŸ” ã‚¨ãƒ©ãƒ¼åˆ†æçµæœ
### æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ç¨®åˆ¥
{self.format_error_types(error_analysis['error_types'])}

### ä¿¡é ¼åº¦
- **åˆ†æä¿¡é ¼åº¦**: {error_analysis['confidence']:.2f}
- **é‡è¦åº¦**: {error_analysis['severity'].value}

### æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
{self.format_suggested_actions(error_analysis['suggested_actions'])}

### å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«
{self.format_affected_files(error_analysis['affected_files'])}

## ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 
```
{project_structure}
```

## ğŸ“„ é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹
{relevant_files}

## ğŸ› ï¸ ä¿®å¾©è¦ä»¶
1. **æ ¹æœ¬åŸå› ã®ç‰¹å®š**: ã‚¨ãƒ©ãƒ¼ã®çœŸã®åŸå› ã‚’ç‰¹å®šã™ã‚‹
2. **æœ€å°é™ã®å¤‰æ›´**: å‰¯ä½œç”¨ã‚’é¿ã‘ã‚‹ãŸã‚æœ€å°é™ã®å¤‰æ›´ã§ä¿®å¾©
3. **ãƒ†ã‚¹ãƒˆå¯èƒ½æ€§**: ä¿®å¾©å†…å®¹ã‚’ãƒ†ã‚¹ãƒˆã§ãã‚‹æ–¹æ³•ã‚’æä¾›
4. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¸ã®å½±éŸ¿ã‚’æœ€å°åŒ–
5. **å¾Œæ–¹äº’æ›æ€§**: æ—¢å­˜æ©Ÿèƒ½ã¸ã®å½±éŸ¿ã‚’é¿ã‘ã‚‹

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
- ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ…é‡ã«æ‰±ã†: {', '.join(self.security_config['critical_files'])}
- èªè¨¼ãƒ»èªå¯é–¢é€£ã®å¤‰æ›´ã¯é¿ã‘ã‚‹
- å¤–éƒ¨ä¾å­˜é–¢ä¿‚ã®è¿½åŠ ã¯æœ€å°é™ã«
- ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å«ã‚€å¤‰æ›´ã¯ç¦æ­¢

## ğŸ“Š å“è³ªã‚²ãƒ¼ãƒˆ
- ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸: {self.config['quality_gates']['coverage_threshold']*100}%ä»¥ä¸Šç¶­æŒ
- Lintã‚¨ãƒ©ãƒ¼: 0ä»¶
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§: æ–°è¦å°å…¥ç¦æ­¢

## ğŸ“¤ æœŸå¾…ã™ã‚‹æˆæœç‰©
1. **ä¿®å¾©ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰**: æœ€å°é™ã®å¤‰æ›´ã§å•é¡Œã‚’è§£æ±º
2. **å¤‰æ›´èª¬æ˜**: ä½•ã‚’å¤‰æ›´ã—ã€ãªãœãã®å¤‰æ›´ãŒå¿…è¦ã‹ã®èª¬æ˜
3. **ãƒ†ã‚¹ãƒˆæ‰‹é †**: ä¿®å¾©å†…å®¹ã‚’æ¤œè¨¼ã™ã‚‹å…·ä½“çš„ãªæ‰‹é †
4. **å½±éŸ¿ç¯„å›²**: å¤‰æ›´ã«ã‚ˆã‚‹å½±éŸ¿ã®è©³ç´°åˆ†æ
5. **å›å¸°ãƒ†ã‚¹ãƒˆ**: æ—¢å­˜æ©Ÿèƒ½ã¸ã®å½±éŸ¿ã‚’ç¢ºèªã™ã‚‹æ‰‹é †

## âš¡ å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: `/media/kensan/LinuxHDD/ITSM-ITmanagementSystem`
ãƒªãƒã‚¸ãƒˆãƒª: `{self.repo_owner}/{self.repo_name}`

ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’åˆ†æã—ã€é©åˆ‡ã§å®‰å…¨ãªä¿®å¾©ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
"""
        
        return prompt

    def format_error_types(self, error_types: List[Dict]) -> str:
        """ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not error_types:
            return "ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ã®ç‰¹å®šãŒã§ãã¾ã›ã‚“ã§ã—ãŸ"
        
        formatted = []
        for error in error_types:
            formatted.append(f"- **{error['type']}**: {error['match']} (é‡è¦åº¦: {error['severity']})")
        
        return '\n'.join(formatted)

    def format_suggested_actions(self, actions: List[str]) -> str:
        """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not actions:
            return "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ã‚Šã¾ã›ã‚“"
        
        return '\n'.join([f"- {action}" for action in actions])

    def format_affected_files(self, files: List[str]) -> str:
        """å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not files:
            return "å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç‰¹å®šã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
        
        return '\n'.join([f"- `{file}`" for file in files[:10]])  # æœ€å¤§10ãƒ•ã‚¡ã‚¤ãƒ«

    async def get_project_structure(self) -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ å–å¾—"""
        try:
            # é‡è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿ã‚’è¡¨ç¤º
            important_paths = [
                "backend/app/",
                "frontend/src/",
                ".github/workflows/",
                "tests/",
                "requirements.txt",
                "package.json"
            ]
            
            structure = []
            for path in important_paths:
                full_path = self.project_root / path
                if full_path.exists():
                    if full_path.is_file():
                        structure.append(f"{path}")
                    else:
                        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
                        try:
                            files = list(full_path.glob("*.py"))[:5]  # æœ€å¤§5ãƒ•ã‚¡ã‚¤ãƒ«
                            if files:
                                structure.append(f"{path}/")
                                for file in files:
                                    structure.append(f"  â””â”€â”€ {file.name}")
                        except:
                            structure.append(f"{path}/")
            
            return '\n'.join(structure)
        except Exception as e:
            return f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®å–å¾—ã«å¤±æ•—: {e}"

    async def get_relevant_files(self, file_paths: List[str]) -> str:
        """é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹å–å¾—"""
        if not file_paths:
            return "é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“"
        
        content_parts = []
        for file_path in file_paths[:3]:  # æœ€å¤§3ãƒ•ã‚¡ã‚¤ãƒ«
            try:
                full_path = self.project_root / file_path
                if full_path.exists() and full_path.is_file():
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ1MBä»¥ä¸‹ï¼‰
                    if full_path.stat().st_size < 1024 * 1024:
                        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()[:2000]  # æœ€å¤§2000æ–‡å­—
                            content_parts.append(f"### {file_path}\n```\n{content}\n```")
            except Exception as e:
                content_parts.append(f"### {file_path}\n```\nãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}\n```")
        
        return '\n\n'.join(content_parts) if content_parts else "é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿å–ã‚ŠãŒã§ãã¾ã›ã‚“ã§ã—ãŸ"

    async def execute_repair_cycle(self, context: RepairContext) -> RepairResult:
        """æ‹¡å¼µä¿®å¾©ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ"""
        self.logger.info(f"Starting enhanced repair cycle for run {context.run_id}")
        
        try:
            # ã‚¨ãƒ©ãƒ¼åˆ†æ
            error_analysis = await self.enhanced_error_analysis(
                context.error_logs, 
                {"id": context.run_id}
            )
            
            # Claudeç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
            prompt = await self.generate_enhanced_claude_prompt(context, error_analysis)
            
            # Claude Flowå®Ÿè¡Œ
            claude_result = await self.claude_flow.execute_repair(prompt, context)
            
            if not claude_result["success"]:
                return RepairResult(
                    success=False,
                    error_message=f"Claude Flow failed: {claude_result.get('error')}",
                    confidence_score=0.0
                )
            
            # æ‰¿èªåˆ¤å®š
            approval_result = await self.approval_system.evaluate_approval(
                claude_result, context, error_analysis
            )
            
            if not approval_result["approved"]:
                return RepairResult(
                    success=False,
                    error_message=f"Manual approval required: {approval_result['reason']}",
                    confidence_score=claude_result.get("confidence", 0.0)
                )
            
            # éš”é›¢ãƒ–ãƒ©ãƒ³ãƒã§ä¿®å¾©é©ç”¨
            repair_result = await self.apply_repair_with_isolation(
                claude_result, context
            )
            
            return repair_result
            
        except Exception as e:
            self.logger.error(f"Error in repair cycle: {e}")
            return RepairResult(
                success=False,
                error_message=str(e),
                confidence_score=0.0
            )

    async def apply_repair_with_isolation(self, claude_result: Dict, context: RepairContext) -> RepairResult:
        """éš”é›¢ç’°å¢ƒã§ã®ä¿®å¾©é©ç”¨"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        branch_name = f"{self.config['security']['isolation_branch_prefix']}-{context.run_id}-{timestamp}"
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            if self.config["security"]["backup_before_repair"]:
                backup_path = await self.create_backup(context.run_id)
                self.logger.info(f"Backup created: {backup_path}")
            
            # ãƒ–ãƒ©ãƒ³ãƒä½œæˆ
            await self.create_isolation_branch(branch_name)
            
            # å¤‰æ›´é©ç”¨
            changes_applied = await self.apply_changes(claude_result["changes"])
            
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            test_result = await self.run_quality_checks()
            
            if not test_result["passed"]:
                self.logger.warning("Quality checks failed, reverting changes")
                await self.revert_to_main()
                return RepairResult(
                    success=False,
                    error_message=f"Quality checks failed: {test_result['errors']}",
                    confidence_score=claude_result.get("confidence", 0.0)
                )
            
            # ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
            pr_url = await self.create_enhanced_pull_request(
                branch_name, claude_result, context, changes_applied
            )
            
            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†å®Ÿè¡Œ
            if context.auto_approve:
                await self.trigger_workflow_rerun(context.run_id)
            
            return RepairResult(
                success=True,
                branch_name=branch_name,
                pr_url=pr_url,
                changes_applied=changes_applied,
                confidence_score=claude_result.get("confidence", 0.0),
                security_impact=context.security_level
            )
            
        except Exception as e:
            self.logger.error(f"Error applying repair: {e}")
            await self.cleanup_failed_repair(branch_name)
            return RepairResult(
                success=False,
                error_message=str(e),
                confidence_score=claude_result.get("confidence", 0.0)
            )

    async def create_backup(self, run_id: str) -> str:
        """ä¿®å¾©å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = self.base_path / "backups" / f"repair_{run_id}_{timestamp}"
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        important_files = [
            "backend/app/",
            "frontend/src/",
            "requirements.txt",
            "package.json",
            ".github/workflows/"
        ]
        
        for file_path in important_files:
            src = self.project_root / file_path
            if src.exists():
                dst = backup_dir / file_path
                if src.is_file():
                    dst.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(src, dst)
                else:
                    shutil.copytree(src, dst, dirs_exist_ok=True)
        
        return str(backup_dir)

    async def create_isolation_branch(self, branch_name: str):
        """éš”é›¢ãƒ–ãƒ©ãƒ³ãƒä½œæˆ"""
        try:
            # æœ€æ–°ã®mainãƒ–ãƒ©ãƒ³ãƒã«æ›´æ–°
            subprocess.run(["git", "checkout", "main"], cwd=self.project_root, check=True)
            subprocess.run(["git", "pull", "origin", "main"], cwd=self.project_root, check=True)
            
            # æ–°ã—ã„ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ
            subprocess.run(
                ["git", "checkout", "-b", branch_name],
                cwd=self.project_root,
                check=True
            )
            
            self.logger.info(f"Created isolation branch: {branch_name}")
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Failed to create isolation branch: {e}")
            raise

    async def apply_changes(self, changes: List[Dict]) -> List[Dict]:
        """å¤‰æ›´é©ç”¨"""
        applied_changes = []
        
        for change in changes:
            try:
                file_path = change.get("file")
                content = change.get("content")
                operation = change.get("operation", "modify")
                
                if not file_path:
                    continue
                
                full_path = self.project_root / file_path
                
                if operation == "create":
                    full_path.parent.mkdir(parents=True, exist_ok=True)
                    with open(full_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    applied_changes.append({
                        "file": file_path,
                        "operation": "created",
                        "lines_changed": len(content.split('\n'))
                    })
                    
                elif operation == "modify":
                    if full_path.exists():
                        with open(full_path, 'w', encoding='utf-8') as f:
                            f.write(content)
                        applied_changes.append({
                            "file": file_path,
                            "operation": "modified",
                            "lines_changed": len(content.split('\n'))
                        })
                        
                elif operation == "delete":
                    if full_path.exists():
                        full_path.unlink()
                        applied_changes.append({
                            "file": file_path,
                            "operation": "deleted",
                            "lines_changed": 0
                        })
                
                self.logger.info(f"Applied {operation} to {file_path}")
                
            except Exception as e:
                self.logger.error(f"Failed to apply change to {file_path}: {e}")
                continue
        
        # å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
        if applied_changes:
            subprocess.run(["git", "add", "."], cwd=self.project_root, check=True)
            commit_message = f"Auto-repair: Apply Claude Flow fixes\n\nFiles modified: {len(applied_changes)}"
            subprocess.run(
                ["git", "commit", "-m", commit_message],
                cwd=self.project_root,
                check=True
            )
        
        return applied_changes

    async def run_quality_checks(self) -> Dict:
        """å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        checks = {
            "lint": False,
            "tests": False,
            "security": False,
            "errors": []
        }
        
        try:
            # Lintãƒã‚§ãƒƒã‚¯
            if self.config["quality_gates"]["lint_pass_requirement"]:
                lint_result = await self.run_lint_checks()
                checks["lint"] = lint_result["passed"]
                if not lint_result["passed"]:
                    checks["errors"].extend(lint_result["errors"])
            
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            if self.config["quality_gates"]["test_pass_requirement"]:
                test_result = await self.run_tests()
                checks["tests"] = test_result["passed"]
                if not test_result["passed"]:
                    checks["errors"].extend(test_result["errors"])
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
            security_result = await self.run_security_scan()
            checks["security"] = security_result["passed"]
            if not security_result["passed"]:
                checks["errors"].extend(security_result["errors"])
            
        except Exception as e:
            checks["errors"].append(f"Quality check error: {e}")
        
        checks["passed"] = all([
            checks["lint"] or not self.config["quality_gates"]["lint_pass_requirement"],
            checks["tests"] or not self.config["quality_gates"]["test_pass_requirement"],
            checks["security"]
        ])
        
        return checks

    async def run_lint_checks(self) -> Dict:
        """Lintãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        try:
            # Python Lint
            python_result = subprocess.run(
                ["flake8", "backend/", "--select=E9,F63,F7,F82"],
                cwd=self.project_root,
                capture_output=True,
                text=True
            )
            
            # TypeScript Lint (if exists)
            ts_result = {"returncode": 0, "stderr": ""}
            if (self.project_root / "frontend" / "package.json").exists():
                ts_result = subprocess.run(
                    ["npm", "run", "lint", "--", "--max-warnings", "0"],
                    cwd=self.project_root / "frontend",
                    capture_output=True,
                    text=True
                )
            
            errors = []
            if python_result.returncode != 0:
                errors.append(f"Python lint errors: {python_result.stdout}")
            if ts_result.returncode != 0:
                errors.append(f"TypeScript lint errors: {ts_result.stderr}")
            
            return {
                "passed": len(errors) == 0,
                "errors": errors
            }
            
        except Exception as e:
            return {
                "passed": False,
                "errors": [f"Lint check failed: {e}"]
            }

    async def run_tests(self) -> Dict:
        """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        try:
            # Backend tests
            backend_result = subprocess.run(
                ["python", "-m", "pytest", "tests/", "-x", "--tb=short"],
                cwd=self.project_root / "backend",
                capture_output=True,
                text=True
            )
            
            # Frontend tests (if exists)
            frontend_result = {"returncode": 0, "stderr": ""}
            if (self.project_root / "frontend" / "package.json").exists():
                frontend_result = subprocess.run(
                    ["npm", "test", "--", "--watchAll=false", "--passWithNoTests"],
                    cwd=self.project_root / "frontend",
                    capture_output=True,
                    text=True
                )
            
            errors = []
            if backend_result.returncode != 0:
                errors.append(f"Backend tests failed: {backend_result.stdout}")
            if frontend_result.returncode != 0:
                errors.append(f"Frontend tests failed: {frontend_result.stderr}")
            
            return {
                "passed": len(errors) == 0,
                "errors": errors
            }
            
        except Exception as e:
            return {
                "passed": False,
                "errors": [f"Test execution failed: {e}"]
            }

    async def run_security_scan(self) -> Dict:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ"""
        try:
            errors = []
            
            # å±é™ºãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
            for pattern in self.security_config["auto_deny_patterns"]:
                result = subprocess.run(
                    ["grep", "-r", pattern, ".", "--exclude-dir=.git"],
                    cwd=self.project_root,
                    capture_output=True,
                    text=True
                )
                if result.returncode == 0:
                    errors.append(f"Dangerous pattern found: {pattern}")
            
            # ä¾å­˜é–¢ä¿‚è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯
            if (self.project_root / "backend" / "requirements.txt").exists():
                safety_result = subprocess.run(
                    ["safety", "check", "-r", "requirements.txt"],
                    cwd=self.project_root / "backend",
                    capture_output=True,
                    text=True
                )
                if safety_result.returncode != 0:
                    errors.append(f"Security vulnerabilities in Python dependencies: {safety_result.stdout}")
            
            return {
                "passed": len(errors) == 0,
                "errors": errors
            }
            
        except Exception as e:
            return {
                "passed": True,  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ã®å¤±æ•—ã¯è­¦å‘Šãƒ¬ãƒ™ãƒ«
                "errors": [f"Security scan warning: {e}"]
            }

    async def create_enhanced_pull_request(self, branch_name: str, claude_result: Dict, 
                                         context: RepairContext, changes_applied: List[Dict]) -> str:
        """æ‹¡å¼µãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ"""
        try:
            title = f"ğŸ¤– Auto-repair: {context.workflow_name} (Run #{context.run_id})"
            
            # è©³ç´°ãªPRæœ¬æ–‡ã‚’ä½œæˆ
            body = self.generate_pr_body(claude_result, context, changes_applied)
            
            # ãƒ©ãƒ™ãƒ«è¨­å®š
            labels = ["auto-repair", f"security-{context.security_level.value}"]
            if context.auto_approve:
                labels.append("auto-approved")
            else:
                labels.append("manual-review-required")
            
            # PRã‚’ä½œæˆ
            cmd = [
                "gh", "pr", "create",
                "--title", title,
                "--body", body,
                "--head", branch_name,
                "--base", "main"
            ]
            
            # ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
            for label in labels:
                cmd.extend(["--label", label])
            
            # ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’è‡ªå‹•ã‚¢ã‚µã‚¤ãƒ³
            if self.config["github"]["auto_assign_reviewers"]:
                cmd.extend(["--reviewer", "@me"])
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            pr_url = result.stdout.strip()
            
            self.logger.info(f"Created enhanced pull request: {pr_url}")
            return pr_url
            
        except Exception as e:
            self.logger.error(f"Failed to create pull request: {e}")
            raise

    def generate_pr_body(self, claude_result: Dict, context: RepairContext, 
                        changes_applied: List[Dict]) -> str:
        """PRæœ¬æ–‡ç”Ÿæˆ"""
        return f"""## ğŸ¤– è‡ªå‹•ä¿®å¾©ãƒ¬ãƒãƒ¼ãƒˆ

### ğŸ“Š ä¿®å¾©ã‚µãƒãƒªãƒ¼
- **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: {context.workflow_name}
- **å®Ÿè¡ŒID**: {context.run_id}
- **ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥**: {context.error_type}
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ™ãƒ«**: {context.security_level.value}
- **ä¿¡é ¼åº¦**: {claude_result.get('confidence', 0.0):.2f}
- **ä¿®å¾©æ™‚åˆ»**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

### ğŸ”§ å®Ÿè¡Œã•ã‚ŒãŸå¤‰æ›´
{self.format_changes_for_pr(changes_applied)}

### ğŸ“ ä¿®å¾©å†…å®¹èª¬æ˜
{claude_result.get('description', 'Claude Flowã«ã‚ˆã‚‹è‡ªå‹•ä¿®å¾©')}

### âœ… å“è³ªãƒã‚§ãƒƒã‚¯çµæœ
- Lintãƒã‚§ãƒƒã‚¯: âœ… åˆæ ¼
- ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: âœ… åˆæ ¼  
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³: âœ… åˆæ ¼

### ğŸ§ª ãƒ†ã‚¹ãƒˆæ‰‹é †
{claude_result.get('test_instructions', 'æ¨™æº–çš„ãªCI/CDãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„')}

### ğŸ¯ å½±éŸ¿ç¯„å›²
{claude_result.get('impact_analysis', 'ã‚¨ãƒ©ãƒ¼ä¿®å¾©ã®ã¿ã§æ—¢å­˜æ©Ÿèƒ½ã¸ã®å½±éŸ¿ã¯æœ€å°é™ã§ã™')}

### âš ï¸ æ³¨æ„äº‹é …
{self.generate_pr_warnings(context, changes_applied)}

### ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
1. ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨æ‰¿èª
2. ãƒãƒ¼ã‚¸å¾Œã®CI/CDç¢ºèª
3. æœ¬ç•ªç’°å¢ƒã¸ã®å½±éŸ¿ç›£è¦–

---
*ã“ã®PRã¯ Enhanced GitHub Actions Auto-Repair System ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
*ä¿®å¾©ã‚¨ãƒ³ã‚¸ãƒ³: Claude Flow MCP Integration*
"""

    def format_changes_for_pr(self, changes: List[Dict]) -> str:
        """PRç”¨å¤‰æ›´ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not changes:
            return "å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
        
        formatted = []
        for change in changes:
            operation = change.get("operation", "modified")
            file_path = change.get("file", "Unknown")
            lines = change.get("lines_changed", 0)
            
            emoji = {"created": "â•", "modified": "âœï¸", "deleted": "âŒ"}.get(operation, "ğŸ“")
            formatted.append(f"{emoji} `{file_path}` ({operation}, {lines} lines)")
        
        return '\n'.join(formatted)

    def generate_pr_warnings(self, context: RepairContext, changes: List[Dict]) -> str:
        """PRè­¦å‘Šç”Ÿæˆ"""
        warnings = []
        
        if context.security_level in [SecurityLevel.HIGH, SecurityLevel.CRITICAL]:
            warnings.append("ğŸš¨ é«˜ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯: æ…é‡ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå¿…è¦")
        
        if not context.auto_approve:
            warnings.append("ğŸ‘€ æ‰‹å‹•æ‰¿èªå¿…é ˆ: è‡ªå‹•ãƒãƒ¼ã‚¸ã¯ç„¡åŠ¹")
        
        security_files_affected = any(
            any(critical in change.get("file", "") for critical in self.security_config["critical_files"])
            for change in changes
        )
        
        if security_files_affected:
            warnings.append("ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™")
        
        if len(changes) > self.config["repair"]["max_file_changes"]:
            warnings.append(f"ğŸ“Š å¤šæ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´: {len(changes)}ãƒ•ã‚¡ã‚¤ãƒ«")
        
        return '\n'.join([f"- {warning}" for warning in warnings]) if warnings else "ç‰¹ã«æ³¨æ„äº‹é …ã¯ã‚ã‚Šã¾ã›ã‚“"

    async def revert_to_main(self):
        """mainãƒ–ãƒ©ãƒ³ãƒã«æˆ»ã‚‹"""
        try:
            subprocess.run(["git", "checkout", "main"], cwd=self.project_root, check=True)
            subprocess.run(["git", "reset", "--hard", "HEAD"], cwd=self.project_root, check=True)
        except Exception as e:
            self.logger.error(f"Failed to revert to main: {e}")

    async def cleanup_failed_repair(self, branch_name: str):
        """å¤±æ•—ã—ãŸä¿®å¾©ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            await self.revert_to_main()
            # ãƒ–ãƒ©ãƒ³ãƒå‰Šé™¤
            subprocess.run(
                ["git", "branch", "-D", branch_name], 
                cwd=self.project_root, 
                check=False
            )
        except Exception as e:
            self.logger.error(f"Failed to cleanup failed repair: {e}")

    async def trigger_workflow_rerun(self, run_id: str) -> bool:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†å®Ÿè¡Œ"""
        try:
            cmd = ["gh", "api", 
                   f"repos/{self.repo_owner}/{self.repo_name}/actions/runs/{run_id}/rerun", 
                   "-X", "POST"]
            
            subprocess.run(cmd, check=True)
            self.logger.info(f"Triggered rerun for workflow {run_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to trigger workflow rerun: {e}")
            return False

    async def get_failed_workflow_runs(self) -> List[Dict]:
        """å¤±æ•—ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚’å–å¾—"""
        try:
            cmd = [
                "gh", "api", 
                f"repos/{self.repo_owner}/{self.repo_name}/actions/runs",
                "--jq", ".workflow_runs[] | select(.conclusion == \"failure\" and .status == \"completed\") | {id: .id, name: .name, conclusion: .conclusion, created_at: .created_at, head_sha: .head_sha}"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            runs_data = result.stdout.strip()
            
            if not runs_data:
                return []
            
            runs = []
            for line in runs_data.split('\n'):
                if line.strip():
                    runs.append(json.loads(line.strip()))
            
            return runs
            
        except Exception as e:
            self.logger.error(f"Failed to get workflow runs: {e}")
            return []

    async def monitoring_loop(self):
        """æ‹¡å¼µç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        self.logger.info("Starting enhanced GitHub Actions monitoring loop")
        self.state["monitoring"] = True
        self.save_state()
        
        while (self.state["monitoring"] and 
               self.state["repair_cycles"] < self.config["repair"]["max_repair_cycles"]):
            try:
                # GitHub CLIèªè¨¼ç¢ºèª
                if not await self.check_github_cli():
                    self.logger.error("GitHub CLI not authenticated")
                    await asyncio.sleep(60)
                    continue
                
                # å¤±æ•—ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚’å–å¾—
                failed_runs = await self.get_failed_workflow_runs()
                
                if failed_runs:
                    self.logger.info(f"Found {len(failed_runs)} failed workflow runs")
                    self.state["consecutive_clean_cycles"] = 0
                    
                    # ä¸¦è¡Œå‡¦ç†åˆ¶é™
                    semaphore = asyncio.Semaphore(self.config["monitoring"]["max_concurrent_repairs"])
                    
                    async def process_run(run_info):
                        async with semaphore:
                            await self.process_failed_run(run_info)
                    
                    # å¤±æ•—ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä¸¦è¡Œå‡¦ç†
                    tasks = [process_run(run_info) for run_info in failed_runs]
                    await asyncio.gather(*tasks, return_exceptions=True)
                    
                else:
                    # ã‚¯ãƒªãƒ¼ãƒ³ã‚µã‚¤ã‚¯ãƒ«
                    self.state["consecutive_clean_cycles"] += 1
                    self.logger.info(f"Clean cycle {self.state['consecutive_clean_cycles']}/{self.config['quality_gates']['required_clean_cycles']}")
                    
                    if self.state["consecutive_clean_cycles"] >= self.config["quality_gates"]["required_clean_cycles"]:
                        self.logger.info("ğŸ‰ Success! All workflow runs are clean for required cycles")
                        break
                
                # æ¬¡ã®ãƒã‚§ãƒƒã‚¯ã¾ã§å¾…æ©Ÿ
                await asyncio.sleep(self.config["monitoring"]["poll_interval"])
                
            except KeyboardInterrupt:
                self.logger.info("Monitoring interrupted by user")
                break
            except Exception as e:
                self.logger.error(f"Error in monitoring loop: {e}")
                await asyncio.sleep(self.config["monitoring"]["retry_delay"])
        
        self.state["monitoring"] = False
        self.save_state()
        self.logger.info("Enhanced GitHub Actions monitoring stopped")

    async def process_failed_run(self, run_info: Dict):
        """å¤±æ•—ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å‡¦ç†"""
        run_id = str(run_info['id'])
        
        # æ—¢ã«ä¿®å¾©ä¸­ã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯
        if run_id in self.state["active_repairs"]:
            return
        
        self.logger.info(f"Processing failed run: {run_id}")
        
        try:
            # ä¿®å¾©é–‹å§‹ã‚’è¨˜éŒ²
            self.state["active_repairs"][run_id] = {
                "started": datetime.now().isoformat(),
                "status": RepairStatus.IN_PROGRESS.value
            }
            self.save_state()
            
            # ã‚¨ãƒ©ãƒ¼åˆ†æ
            error_logs = await self.extract_error_logs(run_id)
            error_analysis = await self.enhanced_error_analysis(error_logs, run_info)
            
            # ä¿®å¾©ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
            context = await self.create_repair_context(run_info, error_analysis)
            
            # ä¿®å¾©å®Ÿè¡Œ
            repair_result = await self.execute_repair_cycle(context)
            
            # çµæœã‚’è¨˜éŒ²
            self.state["active_repairs"][run_id]["status"] = RepairStatus.COMPLETED.value if repair_result.success else RepairStatus.FAILED.value
            self.state["active_repairs"][run_id]["result"] = asdict(repair_result)
            
            # çµ±è¨ˆæ›´æ–°
            self.state["repair_cycles"] += 1
            if repair_result.success:
                self.state["metrics"]["successful_repairs"] += 1
            else:
                self.state["metrics"]["failed_repairs"] += 1
            
            # å±¥æ­´ã«è¿½åŠ 
            self.state["repair_history"].append({
                "run_id": run_id,
                "timestamp": datetime.now().isoformat(),
                "result": asdict(repair_result),
                "context": asdict(context)
            })
            
            self.save_state()
            
            if repair_result.success:
                self.logger.info(f"Successfully repaired run {run_id}")
            else:
                self.logger.warning(f"Failed to repair run {run_id}: {repair_result.error_message}")
                
        except Exception as e:
            self.logger.error(f"Error processing failed run {run_id}: {e}")
            self.state["active_repairs"][run_id]["status"] = RepairStatus.FAILED.value
            self.state["active_repairs"][run_id]["error"] = str(e)
            self.save_state()

    async def check_github_cli(self) -> bool:
        """GitHub CLIèªè¨¼ç¢ºèª"""
        try:
            result = subprocess.run(["gh", "auth", "status"], 
                                  capture_output=True, text=True, check=False)
            return result.returncode == 0
        except Exception as e:
            self.logger.error(f"GitHub CLI check failed: {e}")
            return False

    async def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        await self.monitoring_loop()

    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.state["monitoring"] = False
        self.save_state()

    def get_status_report(self) -> Dict:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¬ãƒãƒ¼ãƒˆå–å¾—"""
        return {
            "monitoring": self.state["monitoring"],
            "repair_cycles": self.state["repair_cycles"],
            "consecutive_clean_cycles": self.state["consecutive_clean_cycles"],
            "metrics": self.state["metrics"],
            "active_repairs": len(self.state["active_repairs"]),
            "last_check": self.state.get("last_check"),
            "config": self.config
        }


class ClaudeFlowIntegration:
    """Claude Flow MCPçµ±åˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_root: Path, logger: logging.Logger):
        self.project_root = project_root
        self.logger = logger

    async def execute_repair(self, prompt: str, context: RepairContext) -> Dict:
        """Claude Flowä¿®å¾©å®Ÿè¡Œ"""
        try:
            # ä¸€æ™‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
                f.write(prompt)
                prompt_file = f.name
            
            self.logger.info("Executing Claude Flow for repair")
            
            # Claude Flow ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
            cmd = [
                "npx", "claude-flow@alpha", "mcp", "start",
                "--prompt", prompt_file,
                "--auto-mode",
                "--timeout", "300"
            ]
            
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=300
            )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(prompt_file)
            
            if result.returncode == 0:
                output = result.stdout
                parsed_result = self.parse_claude_output(output)
                self.logger.info("Claude Flow repair completed successfully")
                return {
                    "success": True,
                    "changes": parsed_result["changes"],
                    "description": parsed_result["description"],
                    "confidence": parsed_result["confidence"],
                    "test_instructions": parsed_result["test_instructions"]
                }
            else:
                self.logger.error(f"Claude Flow failed: {result.stderr}")
                return {
                    "success": False,
                    "error": result.stderr
                }
                
        except Exception as e:
            self.logger.error(f"Error executing Claude Flow: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    def parse_claude_output(self, output: str) -> Dict:
        """Claude Flowå‡ºåŠ›è§£æ"""
        # å®Ÿéš›ã®Claude Flowå‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¿œã˜ã¦å®Ÿè£…
        # ã“ã“ã§ã¯ä»®ã®è§£æãƒ­ã‚¸ãƒƒã‚¯
        
        result = {
            "changes": [],
            "description": "Claude Flowã«ã‚ˆã‚‹è‡ªå‹•ä¿®å¾©",
            "confidence": 0.8,
            "test_instructions": "æ¨™æº–çš„ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„"
        }
        
        # å‡ºåŠ›ã‹ã‚‰å¤‰æ›´æƒ…å ±ã‚’æŠ½å‡º
        # (å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Claude Flowã®å…·ä½“çš„ãªå‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åˆã‚ã›ã‚‹)
        
        return result


class ApprovalSystem:
    """æ‰¿èªã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: Dict, logger: logging.Logger):
        self.config = config
        self.logger = logger

    async def can_auto_approve(self, error_analysis: Dict, run_info: Dict) -> bool:
        """è‡ªå‹•æ‰¿èªå¯èƒ½æ€§åˆ¤å®š"""
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯
        if error_analysis["severity"] >= SecurityLevel.HIGH:
            return False
        
        # ä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯
        if error_analysis["confidence"] < self.config["repair"]["confidence_threshold"]:
            return False
        
        return True

    async def evaluate_approval(self, claude_result: Dict, context: RepairContext, 
                              error_analysis: Dict) -> Dict:
        """æ‰¿èªè©•ä¾¡"""
        
        # è‡ªå‹•æ‰¿èªãƒ«ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯
        if not context.auto_approve:
            return {
                "approved": False,
                "reason": "Security level requires manual approval"
            }
        
        # å¤‰æ›´ç¯„å›²ãƒã‚§ãƒƒã‚¯
        changes = claude_result.get("changes", [])
        if len(changes) > self.config["repair"]["max_file_changes"]:
            return {
                "approved": False,
                "reason": f"Too many file changes: {len(changes)}"
            }
        
        return {
            "approved": True,
            "reason": "Auto-approved based on confidence and security level"
        }


class RepairMetrics:
    """ä¿®å¾©ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.reset()
    
    def reset(self):
        self.total_repairs = 0
        self.successful_repairs = 0
        self.failed_repairs = 0
        self.manual_approvals = 0
        self.auto_approvals = 0
    
    def record_repair(self, success: bool, auto_approved: bool):
        self.total_repairs += 1
        if success:
            self.successful_repairs += 1
        else:
            self.failed_repairs += 1
        
        if auto_approved:
            self.auto_approvals += 1
        else:
            self.manual_approvals += 1
    
    def get_success_rate(self) -> float:
        if self.total_repairs == 0:
            return 0.0
        return self.successful_repairs / self.total_repairs
    
    def get_auto_approval_rate(self) -> float:
        if self.total_repairs == 0:
            return 0.0
        return self.auto_approvals / self.total_repairs


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Starting Enhanced GitHub Actions Auto-Repair System")
    print("ğŸ¤– Claude Flow MCP Integration: Enabled")
    print("ğŸ”’ Security Isolation: Enhanced")
    print("âš¡ Real-time Monitoring: Advanced")
    print("ğŸ¯ Quality Gates: Enforced")
    print("ğŸ“Š Metrics Collection: Enabled")
    print("=" * 70)
    
    system = EnhancedGitHubActionsAutoRepair()
    
    try:
        await system.start_monitoring()
    except KeyboardInterrupt:
        print("\nğŸ›‘ Monitoring stopped by user")
        system.stop_monitoring()
    except Exception as e:
        print(f"âŒ Fatal error: {e}")
        system.stop_monitoring()
    finally:
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
        report = system.get_status_report()
        print("\nğŸ“Š Final Status Report:")
        print(json.dumps(report, indent=2))


if __name__ == "__main__":
    asyncio.run(main())