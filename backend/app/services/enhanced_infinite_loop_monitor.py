"""
å¼·åŒ–ã•ã‚ŒãŸç„¡é™ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼ç›£è¦–ãƒ»ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ  - ITSMãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIçµ±åˆç‰ˆ
- 24æ™‚é–“ç„¡åœæ­¢ç›£è¦–ãƒ»æ¤œçŸ¥ãƒ»ä¿®å¾©
- é«˜åº¦ãªè‡ªå‹•ä¿®å¾©ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆã‚³ãƒ¼ãƒ‰ä¿®æ­£ã€ä¾å­˜é–¢ä¿‚ä¿®å¾©ç­‰ï¼‰
- ITSMã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åŸºæº–æº–æ‹ 
- åŒ…æ‹¬çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- ç¶™ç¶šç›£è¦–ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import asyncio
import aiohttp
import aiofiles
import logging
import time
import json
import traceback
import re
import sqlite3
import subprocess
import os
import hashlib
import psutil
import ssl
import socket
import statistics
from typing import Dict, List, Optional, Any, Tuple, Union, Set
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from urllib.parse import urlparse
import threading
from concurrent.futures import ThreadPoolExecutor
from collections import defaultdict, deque
import asyncio
import signal
import sys

logger = logging.getLogger(__name__)

class RepairStrategy(Enum):
    """ä¿®å¾©æˆ¦ç•¥"""
    IMMEDIATE = "immediate"  # å³åº§ä¿®å¾©
    PROGRESSIVE = "progressive"  # æ®µéšçš„ä¿®å¾©
    CONSERVATIVE = "conservative"  # ä¿å®ˆçš„ä¿®å¾©
    AGGRESSIVE = "aggressive"  # ç©æ¥µçš„ä¿®å¾©

class ValidationLevel(Enum):
    """æ¤œè¨¼ãƒ¬ãƒ™ãƒ«"""
    BASIC = "basic"
    STANDARD = "standard"
    COMPREHENSIVE = "comprehensive"
    EXHAUSTIVE = "exhaustive"

class SystemHealth(Enum):
    """ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§"""
    OPTIMAL = "optimal"
    GOOD = "good"
    DEGRADED = "degraded"
    CRITICAL = "critical"
    EMERGENCY = "emergency"

@dataclass
class RepairAction:
    """ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
    action_id: str
    target: str
    strategy: RepairStrategy
    priority: int  # 1=æœ€é«˜, 5=æœ€ä½
    estimated_time: float
    dependencies: List[str]
    validation_required: ValidationLevel
    rollback_available: bool

@dataclass
class ValidationResult:
    """æ¤œè¨¼çµæœ"""
    timestamp: datetime
    validation_type: str
    target: str
    is_valid: bool
    score: float  # 0-100
    issues: List[str]
    recommendations: List[str]
    execution_time: float

@dataclass
class LoopCycle:
    """ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚¯ãƒ«æƒ…å ±"""
    cycle_id: str
    start_time: datetime
    end_time: Optional[datetime]
    errors_detected: int
    repairs_attempted: int
    repairs_successful: int
    validation_score: float
    system_health: SystemHealth
    performance_metrics: Dict[str, float]

class EnhancedInfiniteLoopMonitor:
    """å¼·åŒ–ã•ã‚ŒãŸç„¡é™ãƒ«ãƒ¼ãƒ—è‡ªå‹•ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, base_url: str = "http://192.168.3.135:8000"):
        self.base_url = base_url
        self.backend_path = Path("/media/kensan/LinuxHDD/ITSM-ITmanagementSystem/backend")
        self.coordination_path = Path("/media/kensan/LinuxHDD/ITSM-ITmanagementSystem/coordination")
        
        # ç›£è¦–çŠ¶æ…‹
        self.monitoring = False
        self.loop_count = 0
        self.total_errors_fixed = 0
        self.start_time = datetime.now()
        
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
        self.errors: deque = deque(maxlen=10000)
        self.repairs: deque = deque(maxlen=5000)
        self.validations: deque = deque(maxlen=5000)
        self.loop_cycles: List[LoopCycle] = []
        self.system_metrics: Dict[str, Any] = {}
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
        self.response_times: deque = deque(maxlen=1000)
        self.error_rates: deque = deque(maxlen=100)
        self.cpu_usage: deque = deque(maxlen=100)
        self.memory_usage: deque = deque(maxlen=100)
        
        # è¨­å®šå¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.config = {
            "loop_interval": 15,  # åŸºæœ¬ãƒ«ãƒ¼ãƒ—é–“éš”(ç§’)
            "rapid_mode_threshold": 5,  # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰é–¾å€¤(ã‚¨ãƒ©ãƒ¼æ•°)
            "emergency_threshold": 10,  # ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰é–¾å€¤(ã‚¨ãƒ©ãƒ¼æ•°)
            "max_repair_attempts": 3,  # æœ€å¤§ä¿®å¾©è©¦è¡Œå›æ•°
            "validation_timeout": 30,  # æ¤œè¨¼ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ(ç§’)
            "health_check_endpoints": [
                "/health",
                "/docs",
                "/api/v1/incidents",
                "/api/v1/users",
                "/api/v1/dashboard/metrics",
                "/api/v1/problems",
                "/api/v1/changes",
                "/api/v1/notifications"
            ],
            "critical_endpoints": [
                "/api/v1/incidents",
                "/api/v1/auth/login",
                "/api/v1/dashboard/metrics"
            ]
        }
        
        # ä¿®å¾©æˆ¦ç•¥ãƒãƒƒãƒ”ãƒ³ã‚°
        self.repair_strategies = {
            "database_error": RepairStrategy.IMMEDIATE,
            "auth_error": RepairStrategy.PROGRESSIVE,
            "validation_error": RepairStrategy.CONSERVATIVE,
            "performance_issue": RepairStrategy.PROGRESSIVE,
            "security_threat": RepairStrategy.AGGRESSIVE,
            "dependency_error": RepairStrategy.IMMEDIATE
        }
        
        # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨è‡ªå‹•ä¿®å¾©ãƒãƒƒãƒ”ãƒ³ã‚°
        self.auto_repair_patterns = {
            r"ImportError.*cannot import.*'(\w+)'.*from.*'([\w\.]+)'": self._fix_import_error,
            r"ModuleNotFoundError.*No module named.*'([\w\.]+)'": self._fix_module_not_found,
            r"AttributeError.*'(\w+)'.*object has no attribute.*'(\w+)'": self._fix_attribute_error,
            r"sqlite3\.OperationalError.*database.*locked": self._fix_database_lock,
            r"sqlite3\.OperationalError.*no such table": self._fix_missing_table,
            r"Connection refused": self._fix_connection_refused,
            r"HTTP 404.*Not Found": self._fix_endpoint_not_found,
            r"HTTP 500.*Internal Server Error": self._fix_server_error,
            r"Validation error.*required field": self._fix_validation_error,
            r"FOREIGN KEY constraint failed": self._fix_foreign_key_error
        }
        
    async def start_infinite_loop_monitoring(self):
        """ç„¡é™ãƒ«ãƒ¼ãƒ—ç›£è¦–é–‹å§‹"""
        logger.info("ğŸš€ å¼·åŒ–ã•ã‚ŒãŸç„¡é™ãƒ«ãƒ¼ãƒ—è‡ªå‹•ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
        self.monitoring = True
        self.start_time = datetime.now()
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        try:
            while self.monitoring:
                cycle_start = datetime.now()
                cycle_id = f"cycle_{self.loop_count:06d}_{int(cycle_start.timestamp())}"
                
                # ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹
                current_cycle = LoopCycle(
                    cycle_id=cycle_id,
                    start_time=cycle_start,
                    end_time=None,
                    errors_detected=0,
                    repairs_attempted=0,
                    repairs_successful=0,
                    validation_score=0.0,
                    system_health=SystemHealth.GOOD,
                    performance_metrics={}
                )
                
                logger.info(f"ğŸ”„ ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚¯ãƒ« {self.loop_count} é–‹å§‹ (ID: {cycle_id})")
                
                # 1. åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥
                errors_detected = await self._comprehensive_error_detection()
                current_cycle.errors_detected = len(errors_detected)
                
                # 2. å‹•çš„é–“éš”èª¿æ•´
                interval = self._calculate_dynamic_interval(errors_detected)
                
                # 3. ä¸¦åˆ—ä¿®å¾©å®Ÿè¡Œ
                if errors_detected:
                    repairs_result = await self._parallel_repair_execution(errors_detected)
                    current_cycle.repairs_attempted = repairs_result["attempted"]
                    current_cycle.repairs_successful = repairs_result["successful"]
                    self.total_errors_fixed += repairs_result["successful"]
                
                # 4. åŒ…æ‹¬çš„æ¤œè¨¼
                validation_result = await self._comprehensive_validation()
                current_cycle.validation_score = validation_result["overall_score"]
                
                # 5. ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§è©•ä¾¡
                current_cycle.system_health = await self._assess_system_health()
                
                # 6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
                current_cycle.performance_metrics = await self._collect_performance_metrics()
                
                # 7. ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚¯ãƒ«å®Œäº†
                current_cycle.end_time = datetime.now()
                self.loop_cycles.append(current_cycle)
                
                # 8. çŠ¶æ…‹ä¿å­˜
                await self._save_enhanced_state()
                
                # 9. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                if self.loop_count % 10 == 0:  # 10ã‚µã‚¤ã‚¯ãƒ«ã”ã¨
                    await self._generate_cycle_report()
                
                self.loop_count += 1
                
                # æ¬¡ã®ã‚µã‚¤ã‚¯ãƒ«ã¾ã§å¾…æ©Ÿ
                logger.info(f"âœ… ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚¯ãƒ« {self.loop_count-1} å®Œäº† ({interval}ç§’å¾Œã«æ¬¡å›å®Ÿè¡Œ)")
                await asyncio.sleep(interval)
                
        except Exception as e:
            logger.error(f"âŒ ç„¡é™ãƒ«ãƒ¼ãƒ—ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
        finally:
            await self._cleanup_and_shutdown()
    
    async def _comprehensive_error_detection(self) -> List[Dict[str, Any]]:
        """åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥"""
        errors = []
        
        # ä¸¦åˆ—å®Ÿè¡Œã§ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥
        detection_tasks = [
            self._detect_api_errors(),
            self._detect_database_errors(),
            self._detect_security_threats(),
            self._detect_performance_issues(),
            self._detect_dependency_errors(),
            self._detect_configuration_errors()
        ]
        
        detection_results = await asyncio.gather(*detection_tasks, return_exceptions=True)
        
        for result in detection_results:
            if isinstance(result, Exception):
                logger.error(f"ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥ä¸­ã®ä¾‹å¤–: {result}")
            elif isinstance(result, list):
                errors.extend(result)
        
        # ã‚¨ãƒ©ãƒ¼ã®é‡è¤‡æ’é™¤ã¨å„ªå…ˆåº¦ä»˜ã‘
        unique_errors = self._deduplicate_and_prioritize_errors(errors)
        
        logger.info(f"ğŸ” {len(unique_errors)}ä»¶ã®ã‚¨ãƒ©ãƒ¼ã‚’æ¤œçŸ¥")
        return unique_errors
    
    async def _detect_api_errors(self) -> List[Dict[str, Any]]:
        """API ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥"""
        errors = []
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
            for endpoint in self.config["health_check_endpoints"]:
                try:
                    start_time = time.time()
                    url = f"{self.base_url}{endpoint}"
                    
                    async with session.get(url) as response:
                        response_time = time.time() - start_time
                        self.response_times.append(response_time)
                        
                        if response.status >= 400:
                            error_text = await response.text()
                            errors.append({
                                "type": "api_error",
                                "endpoint": endpoint,
                                "status_code": response.status,
                                "error_text": error_text,
                                "response_time": response_time,
                                "severity": "high" if response.status >= 500 else "medium",
                                "timestamp": datetime.now().isoformat()
                            })
                        
                        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã®æ¤œçŸ¥
                        if response_time > 5.0:
                            errors.append({
                                "type": "performance_issue",
                                "endpoint": endpoint,
                                "response_time": response_time,
                                "severity": "medium",
                                "timestamp": datetime.now().isoformat()
                            })
                            
                except Exception as e:
                    errors.append({
                        "type": "connection_error",
                        "endpoint": endpoint,
                        "error": str(e),
                        "severity": "high",
                        "timestamp": datetime.now().isoformat()
                    })
        
        return errors
    
    async def _detect_database_errors(self) -> List[Dict[str, Any]]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥"""
        errors = []
        
        try:
            db_path = self.backend_path / "itsm.db"
            
            if not db_path.exists():
                errors.append({
                    "type": "database_missing",
                    "severity": "critical",
                    "message": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“",
                    "timestamp": datetime.now().isoformat()
                })
                return errors
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
            conn = sqlite3.connect(str(db_path), timeout=5.0)
            
            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            try:
                result = conn.execute("PRAGMA integrity_check").fetchone()
                if result[0] != "ok":
                    errors.append({
                        "type": "database_integrity",
                        "severity": "critical",
                        "message": f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼: {result[0]}",
                        "timestamp": datetime.now().isoformat()
                    })
            except Exception as e:
                errors.append({
                    "type": "database_integrity_check_failed",
                    "severity": "high",
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                })
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            required_tables = ["incidents", "users", "problems", "changes"]
            for table in required_tables:
                try:
                    conn.execute(f"SELECT COUNT(*) FROM {table} LIMIT 1")
                except sqlite3.OperationalError as e:
                    if "no such table" in str(e):
                        errors.append({
                            "type": "missing_table",
                            "table": table,
                            "severity": "high",
                            "timestamp": datetime.now().isoformat()
                        })
            
            conn.close()
            
        except sqlite3.OperationalError as e:
            if "database is locked" in str(e):
                errors.append({
                    "type": "database_locked",
                    "severity": "medium",
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                })
            else:
                errors.append({
                    "type": "database_error",
                    "severity": "high",
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                })
        except Exception as e:
            errors.append({
                "type": "database_connection_error",
                "severity": "high",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
        
        return errors
    
    async def _detect_security_threats(self) -> List[Dict[str, Any]]:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„…å¨æ¤œçŸ¥"""
        errors = []
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„…å¨ã‚’æ¤œçŸ¥
        log_files = [
            self.backend_path / "logs" / "itsm_error.log",
            self.backend_path / "logs" / "itsm_audit.log"
        ]
        
        security_patterns = [
            (r"sql injection", "critical"),
            (r"xss attack", "high"),
            (r"brute force", "high"),
            (r"unauthorized access", "medium"),
            (r"suspicious activity", "medium")
        ]
        
        for log_file in log_files:
            if log_file.exists():
                try:
                    with open(log_file, 'r') as f:
                        recent_lines = f.readlines()[-1000:]  # æœ€æ–°1000è¡Œ
                    
                    for line in recent_lines:
                        for pattern, severity in security_patterns:
                            if re.search(pattern, line, re.IGNORECASE):
                                errors.append({
                                    "type": "security_threat",
                                    "pattern": pattern,
                                    "severity": severity,
                                    "log_line": line.strip(),
                                    "timestamp": datetime.now().isoformat()
                                })
                except Exception as e:
                    logger.error(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„…å¨æ¤œçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
        
        return errors
    
    async def _detect_performance_issues(self) -> List[Dict[str, Any]]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œæ¤œçŸ¥"""
        errors = []
        
        # CPUãƒ»ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        cpu_percent = psutil.cpu_percent(interval=1)
        memory_percent = psutil.virtual_memory().percent
        
        self.cpu_usage.append(cpu_percent)
        self.memory_usage.append(memory_percent)
        
        if cpu_percent > 80:
            errors.append({
                "type": "high_cpu_usage",
                "value": cpu_percent,
                "severity": "high" if cpu_percent > 90 else "medium",
                "timestamp": datetime.now().isoformat()
            })
        
        if memory_percent > 85:
            errors.append({
                "type": "high_memory_usage",
                "value": memory_percent,
                "severity": "high" if memory_percent > 95 else "medium",
                "timestamp": datetime.now().isoformat()
            })
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®çµ±è¨ˆåˆ†æ
        if len(self.response_times) > 10:
            avg_response_time = statistics.mean(self.response_times)
            if avg_response_time > 3.0:
                errors.append({
                    "type": "slow_response_time",
                    "average_time": avg_response_time,
                    "severity": "medium",
                    "timestamp": datetime.now().isoformat()
                })
        
        return errors
    
    async def _detect_dependency_errors(self) -> List[Dict[str, Any]]:
        """ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥"""
        errors = []
        
        # Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
        critical_modules = [
            "fastapi", "sqlalchemy", "pydantic", "sqlite3",
            "asyncio", "aiohttp", "uvicorn"
        ]
        
        for module in critical_modules:
            try:
                __import__(module)
            except ImportError as e:
                errors.append({
                    "type": "dependency_error",
                    "module": module,
                    "error": str(e),
                    "severity": "critical",
                    "timestamp": datetime.now().isoformat()
                })
        
        return errors
    
    async def _detect_configuration_errors(self) -> List[Dict[str, Any]]:
        """è¨­å®šã‚¨ãƒ©ãƒ¼æ¤œçŸ¥"""
        errors = []
        
        # é‡è¦ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        config_files = [
            self.backend_path / "app" / "core" / "config.py",
            self.backend_path / "app" / "main.py",
            self.backend_path / "requirements.txt"
        ]
        
        for config_file in config_files:
            if not config_file.exists():
                errors.append({
                    "type": "configuration_error",
                    "file": str(config_file),
                    "error": "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“",
                    "severity": "high",
                    "timestamp": datetime.now().isoformat()
                })
        
        return errors
    
    def _deduplicate_and_prioritize_errors(self, errors: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ã‚¨ãƒ©ãƒ¼ã®é‡è¤‡æ’é™¤ã¨å„ªå…ˆåº¦ä»˜ã‘"""
        # é‡è¤‡æ’é™¤
        seen = set()
        unique_errors = []
        
        for error in errors:
            error_key = f"{error['type']}_{error.get('endpoint', '')}_{error.get('message', '')}"
            if error_key not in seen:
                seen.add(error_key)
                unique_errors.append(error)
        
        # å„ªå…ˆåº¦ä»˜ã‘ï¼ˆseverityé †ï¼‰
        severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
        unique_errors.sort(key=lambda x: severity_order.get(x.get("severity", "low"), 3))
        
        return unique_errors
    
    def _calculate_dynamic_interval(self, errors: List[Dict[str, Any]]) -> int:
        """å‹•çš„é–“éš”è¨ˆç®—"""
        base_interval = self.config["loop_interval"]
        error_count = len(errors)
        
        if error_count >= self.config["emergency_threshold"]:
            return max(5, base_interval // 4)  # ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰: æœ€çŸ­5ç§’
        elif error_count >= self.config["rapid_mode_threshold"]:
            return max(8, base_interval // 2)  # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰: åŠåˆ†ã®é–“éš”
        elif error_count == 0:
            return min(60, base_interval * 2)  # æ­£å¸¸æ™‚: é–“éš”ã‚’å»¶é•·
        else:
            return base_interval
    
    async def _parallel_repair_execution(self, errors: List[Dict[str, Any]]) -> Dict[str, int]:
        """ä¸¦åˆ—ä¿®å¾©å®Ÿè¡Œ"""
        repair_tasks = []
        
        for error in errors[:10]:  # æœ€å¤§10ä»¶ã¾ã§ä¸¦åˆ—å‡¦ç†
            task = asyncio.create_task(self._execute_single_repair(error))
            repair_tasks.append(task)
        
        results = await asyncio.gather(*repair_tasks, return_exceptions=True)
        
        attempted = len(repair_tasks)
        successful = sum(1 for result in results if result is True)
        
        logger.info(f"ğŸ”§ ä¿®å¾©å®Ÿè¡Œçµæœ: {successful}/{attempted}ä»¶æˆåŠŸ")
        
        return {"attempted": attempted, "successful": successful}
    
    async def _execute_single_repair(self, error: Dict[str, Any]) -> bool:
        """å˜ä¸€ã‚¨ãƒ©ãƒ¼ã®ä¿®å¾©å®Ÿè¡Œ"""
        error_type = error.get("type")
        
        try:
            # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸä¿®å¾©å‡¦ç†
            if error_type == "database_missing":
                return await self._repair_missing_database()
            elif error_type == "database_locked":
                return await self._repair_database_lock()
            elif error_type == "missing_table":
                return await self._repair_missing_table(error.get("table"))
            elif error_type == "api_error":
                return await self._repair_api_error(error)
            elif error_type == "dependency_error":
                return await self._repair_dependency_error(error)
            elif error_type == "configuration_error":
                return await self._repair_configuration_error(error)
            else:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ä¿®å¾©
                return await self._pattern_based_repair(error)
                
        except Exception as e:
            logger.error(f"ä¿®å¾©å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ ({error_type}): {e}")
            return False
    
    async def _repair_missing_database(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        try:
            init_script = self.backend_path / "init_sqlite_db.py"
            if init_script.exists():
                result = subprocess.run(
                    ["python3", str(init_script)],
                    cwd=str(self.backend_path),
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                if result.returncode == 0:
                    logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
                    return True
                else:
                    logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å¤±æ•—: {result.stderr}")
            
            return False
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def _repair_database_lock(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ãƒƒã‚¯è§£é™¤"""
        try:
            # ä¸€å®šæ™‚é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰ãƒªãƒˆãƒ©ã‚¤
            await asyncio.sleep(2)
            
            db_path = self.backend_path / "itsm.db"
            conn = sqlite3.connect(str(db_path), timeout=10.0)
            conn.execute("SELECT 1")
            conn.close()
            
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ãƒƒã‚¯ã‚’è§£é™¤ã—ã¾ã—ãŸ")
            return True
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ãƒƒã‚¯è§£é™¤ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def _repair_missing_table(self, table_name: str) -> bool:
        """ä¸è¶³ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
            init_script = self.backend_path / "init_sqlite_db.py"
            if init_script.exists():
                result = subprocess.run(
                    ["python3", str(init_script)],
                    cwd=str(self.backend_path),
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                if result.returncode == 0:
                    logger.info(f"âœ… ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã‚’ä½œæˆã—ã¾ã—ãŸ")
                    return True
            
            return False
        except Exception as e:
            logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def _repair_api_error(self, error: Dict[str, Any]) -> bool:
        """API ã‚¨ãƒ©ãƒ¼ä¿®å¾©"""
        endpoint = error.get("endpoint")
        status_code = error.get("status_code")
        
        try:
            if status_code == 404:
                # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…ç¢ºèª
                return await self._ensure_endpoint_implementation(endpoint)
            elif status_code >= 500:
                # ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å†èµ·å‹•ã‚’æ¤œè¨
                return await self._restart_server_if_needed()
            
            return False
        except Exception as e:
            logger.error(f"APIä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def _repair_dependency_error(self, error: Dict[str, Any]) -> bool:
        """ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼ä¿®å¾©"""
        module = error.get("module")
        
        try:
            # pip install ã§ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
            result = subprocess.run(
                ["pip3", "install", module],
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.returncode == 0:
                logger.info(f"âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« {module} ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ãŸ")
                return True
            else:
                logger.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"ä¾å­˜é–¢ä¿‚ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def _repair_configuration_error(self, error: Dict[str, Any]) -> bool:
        """è¨­å®šã‚¨ãƒ©ãƒ¼ä¿®å¾©"""
        file_path = error.get("file")
        
        try:
            # åŸºæœ¬çš„ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
            if "config.py" in file_path:
                return await self._create_config_file()
            elif "main.py" in file_path:
                return await self._create_main_file()
            elif "requirements.txt" in file_path:
                return await self._create_requirements_file()
            
            return False
        except Exception as e:
            logger.error(f"è¨­å®šä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def _pattern_based_repair(self, error: Dict[str, Any]) -> bool:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ä¿®å¾©"""
        error_text = error.get("error", "") + error.get("message", "")
        
        for pattern, repair_func in self.auto_repair_patterns.items():
            match = re.search(pattern, error_text)
            if match:
                try:
                    return await repair_func(match, error)
                except Exception as e:
                    logger.error(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ä¿®å¾©ã‚¨ãƒ©ãƒ¼ ({pattern}): {e}")
        
        return False
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³ä¿®å¾©é–¢æ•°ç¾¤
    async def _fix_import_error(self, match, error: Dict[str, Any]) -> bool:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ä¿®å¾©"""
        # æ—¢å­˜ã® auto_repair_engine.py ã®å®Ÿè£…ã‚’å‚è€ƒã«
        return False
    
    async def _fix_module_not_found(self, match, error: Dict[str, Any]) -> bool:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æœªç™ºè¦‹ä¿®å¾©"""
        # æ—¢å­˜ã® auto_repair_engine.py ã®å®Ÿè£…ã‚’å‚è€ƒã«
        return False
    
    async def _fix_attribute_error(self, match, error: Dict[str, Any]) -> bool:
        """å±æ€§ã‚¨ãƒ©ãƒ¼ä¿®å¾©"""
        # æ—¢å­˜ã® auto_repair_engine.py ã®å®Ÿè£…ã‚’å‚è€ƒã«
        return False
    
    async def _fix_database_lock(self, match, error: Dict[str, Any]) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ãƒƒã‚¯ä¿®å¾©"""
        return await self._repair_database_lock()
    
    async def _fix_missing_table(self, match, error: Dict[str, Any]) -> bool:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ä¸è¶³ä¿®å¾©"""
        return await self._repair_missing_database()
    
    async def _fix_connection_refused(self, match, error: Dict[str, Any]) -> bool:
        """æ¥ç¶šæ‹’å¦ä¿®å¾©"""
        return await self._restart_server_if_needed()
    
    async def _fix_endpoint_not_found(self, match, error: Dict[str, Any]) -> bool:
        """ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæœªç™ºè¦‹ä¿®å¾©"""
        return await self._ensure_endpoint_implementation(error.get("endpoint"))
    
    async def _fix_server_error(self, match, error: Dict[str, Any]) -> bool:
        """ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ä¿®å¾©"""
        return await self._restart_server_if_needed()
    
    async def _fix_validation_error(self, match, error: Dict[str, Any]) -> bool:
        """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ä¿®å¾©"""
        # ã‚¹ã‚­ãƒ¼ãƒä¿®æ­£
        return False
    
    async def _fix_foreign_key_error(self, match, error: Dict[str, Any]) -> bool:
        """å¤–éƒ¨ã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ä¿®å¾©"""
        return await self._repair_missing_database()
    
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
    async def _ensure_endpoint_implementation(self, endpoint: str) -> bool:
        """ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…ç¢ºèª"""
        # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å®Ÿè£…çŠ¶æ³ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ä½œæˆ
        return False
    
    async def _restart_server_if_needed(self) -> bool:
        """å¿…è¦ã«å¿œã˜ã¦ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•"""
        # é‡è¦: ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•ã®å®Ÿè£…ã¯æ…é‡ã«
        return False
    
    async def _create_config_file(self) -> bool:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        # åŸºæœ¬çš„ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        return False
    
    async def _create_main_file(self) -> bool:
        """ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        # åŸºæœ¬çš„ãªãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        return False
    
    async def _create_requirements_file(self) -> bool:
        """requirements.txtä½œæˆ"""
        # åŸºæœ¬çš„ãªä¾å­˜é–¢ä¿‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        return False
    
    async def _comprehensive_validation(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„æ¤œè¨¼"""
        validation_results = []
        
        # ä¸¦åˆ—æ¤œè¨¼å®Ÿè¡Œ
        validation_tasks = [
            self._validate_api_functionality(),
            self._validate_database_integrity(),
            self._validate_security_state(),
            self._validate_performance_metrics()
        ]
        
        results = await asyncio.gather(*validation_tasks, return_exceptions=True)
        
        overall_score = 0.0
        valid_results = 0
        
        for result in results:
            if isinstance(result, dict) and "score" in result:
                validation_results.append(result)
                overall_score += result["score"]
                valid_results += 1
        
        overall_score = overall_score / valid_results if valid_results > 0 else 0.0
        
        return {
            "overall_score": overall_score,
            "validation_results": validation_results,
            "timestamp": datetime.now().isoformat()
        }
    
    async def _validate_api_functionality(self) -> Dict[str, Any]:
        """APIæ©Ÿèƒ½æ¤œè¨¼"""
        score = 0.0
        issues = []
        
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
                total_endpoints = len(self.config["health_check_endpoints"])
                working_endpoints = 0
                
                for endpoint in self.config["health_check_endpoints"]:
                    try:
                        async with session.get(f"{self.base_url}{endpoint}") as response:
                            if response.status < 400:
                                working_endpoints += 1
                            else:
                                issues.append(f"ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ {endpoint} ã§ã‚¨ãƒ©ãƒ¼: HTTP {response.status}")
                    except Exception as e:
                        issues.append(f"ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ {endpoint} ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                
                score = (working_endpoints / total_endpoints) * 100 if total_endpoints > 0 else 0
                
        except Exception as e:
            issues.append(f"APIæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return {
            "validation_type": "api_functionality",
            "score": score,
            "issues": issues,
            "timestamp": datetime.now().isoformat()
        }
    
    async def _validate_database_integrity(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§æ¤œè¨¼"""
        score = 0.0
        issues = []
        
        try:
            db_path = self.backend_path / "itsm.db"
            
            if not db_path.exists():
                issues.append("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return {
                    "validation_type": "database_integrity",
                    "score": 0.0,
                    "issues": issues,
                    "timestamp": datetime.now().isoformat()
                }
            
            conn = sqlite3.connect(str(db_path), timeout=10.0)
            
            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            result = conn.execute("PRAGMA integrity_check").fetchone()
            if result[0] == "ok":
                score += 50
            else:
                issues.append(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼: {result[0]}")
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèª
            required_tables = ["incidents", "users", "problems", "changes"]
            existing_tables = 0
            
            for table in required_tables:
                try:
                    conn.execute(f"SELECT COUNT(*) FROM {table} LIMIT 1")
                    existing_tables += 1
                except sqlite3.OperationalError:
                    issues.append(f"ãƒ†ãƒ¼ãƒ–ãƒ« {table} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            
            score += (existing_tables / len(required_tables)) * 50
            conn.close()
            
        except Exception as e:
            issues.append(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return {
            "validation_type": "database_integrity",
            "score": score,
            "issues": issues,
            "timestamp": datetime.now().isoformat()
        }
    
    async def _validate_security_state(self) -> Dict[str, Any]:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£çŠ¶æ…‹æ¤œè¨¼"""
        score = 100.0  # åˆæœŸå€¤
        issues = []
        
        try:
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°ã®ãƒã‚§ãƒƒã‚¯
            security_log = self.backend_path / "logs" / "itsm_audit.log"
            if security_log.exists():
                with open(security_log, 'r') as f:
                    recent_lines = f.readlines()[-100:]  # æœ€æ–°100è¡Œ
                
                threat_count = 0
                for line in recent_lines:
                    if any(threat in line.lower() for threat in ["attack", "threat", "intrusion"]):
                        threat_count += 1
                
                if threat_count > 0:
                    score -= min(threat_count * 10, 50)  # æœ€å¤§50ç‚¹æ¸›ç‚¹
                    issues.append(f"{threat_count}ä»¶ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„…å¨ã‚’æ¤œçŸ¥")
            
        except Exception as e:
            issues.append(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return {
            "validation_type": "security_state",
            "score": max(0, score),
            "issues": issues,
            "timestamp": datetime.now().isoformat()
        }
    
    async def _validate_performance_metrics(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¤œè¨¼"""
        score = 100.0
        issues = []
        
        try:
            # CPUä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
            if len(self.cpu_usage) > 0:
                avg_cpu = statistics.mean(self.cpu_usage)
                if avg_cpu > 80:
                    score -= 30
                    issues.append(f"CPUä½¿ç”¨ç‡ãŒé«˜ã„: {avg_cpu:.1f}%")
                elif avg_cpu > 60:
                    score -= 15
                    issues.append(f"CPUä½¿ç”¨ç‡ãŒä¸­ç¨‹åº¦: {avg_cpu:.1f}%")
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
            if len(self.memory_usage) > 0:
                avg_memory = statistics.mean(self.memory_usage)
                if avg_memory > 85:
                    score -= 30
                    issues.append(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„: {avg_memory:.1f}%")
                elif avg_memory > 70:
                    score -= 15
                    issues.append(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒä¸­ç¨‹åº¦: {avg_memory:.1f}%")
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãƒã‚§ãƒƒã‚¯
            if len(self.response_times) > 0:
                avg_response = statistics.mean(self.response_times)
                if avg_response > 5.0:
                    score -= 25
                    issues.append(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒé…ã„: {avg_response:.2f}ç§’")
                elif avg_response > 2.0:
                    score -= 10
                    issues.append(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒä¸­ç¨‹åº¦: {avg_response:.2f}ç§’")
            
        except Exception as e:
            issues.append(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return {
            "validation_type": "performance_metrics",
            "score": max(0, score),
            "issues": issues,
            "timestamp": datetime.now().isoformat()
        }
    
    async def _assess_system_health(self) -> SystemHealth:
        """ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§è©•ä¾¡"""
        try:
            # æœ€æ–°ã®æ¤œè¨¼çµæœã‹ã‚‰ç·åˆè©•ä¾¡
            if len(self.validations) == 0:
                return SystemHealth.GOOD
            
            recent_validations = list(self.validations)[-5:]  # æœ€æ–°5ä»¶
            avg_score = statistics.mean([v.score for v in recent_validations])
            
            if avg_score >= 90:
                return SystemHealth.OPTIMAL
            elif avg_score >= 75:
                return SystemHealth.GOOD
            elif avg_score >= 50:
                return SystemHealth.DEGRADED
            elif avg_score >= 25:
                return SystemHealth.CRITICAL
            else:
                return SystemHealth.EMERGENCY
                
        except Exception:
            return SystemHealth.DEGRADED
    
    async def _collect_performance_metrics(self) -> Dict[str, float]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        metrics = {}
        
        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics["cpu_percent"] = psutil.cpu_percent()
            metrics["memory_percent"] = psutil.virtual_memory().percent
            metrics["disk_percent"] = psutil.disk_usage('/').percent
            
            # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            if len(self.response_times) > 0:
                metrics["avg_response_time"] = statistics.mean(self.response_times)
                metrics["max_response_time"] = max(self.response_times)
                metrics["min_response_time"] = min(self.response_times)
            
            # ã‚¨ãƒ©ãƒ¼ç‡
            if len(self.error_rates) > 0:
                metrics["error_rate"] = statistics.mean(self.error_rates)
            
            # ç›£è¦–ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            metrics["total_errors_detected"] = len(self.errors)
            metrics["total_repairs_attempted"] = len(self.repairs)
            metrics["uptime_hours"] = (datetime.now() - self.start_time).total_seconds() / 3600
            
        except Exception as e:
            logger.error(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¨ãƒ©ãƒ¼: {e}")
        
        return metrics
    
    async def _save_enhanced_state(self):
        """æ‹¡å¼µçŠ¶æ…‹ä¿å­˜"""
        try:
            state = {
                "loop_count": self.loop_count,
                "total_errors_fixed": self.total_errors_fixed,
                "last_scan": datetime.now().isoformat(),
                "monitoring_since": self.start_time.isoformat(),
                "current_health": self._assess_system_health().value if hasattr(self, '_assess_system_health') else "unknown",
                "recent_metrics": await self._collect_performance_metrics(),
                "repair_history": [
                    {
                        "cycle_id": cycle.cycle_id,
                        "timestamp": cycle.start_time.isoformat(),
                        "errors_detected": cycle.errors_detected,
                        "repairs_successful": cycle.repairs_successful,
                        "validation_score": cycle.validation_score,
                        "system_health": cycle.system_health.value
                    }
                    for cycle in self.loop_cycles[-20:]  # æœ€æ–°20ã‚µã‚¤ã‚¯ãƒ«
                ]
            }
            
            state_file = self.coordination_path / "enhanced_infinite_loop_state.json"
            async with aiofiles.open(state_file, 'w') as f:
                await f.write(json.dumps(state, indent=2, ensure_ascii=False))
                
        except Exception as e:
            logger.error(f"çŠ¶æ…‹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _generate_cycle_report(self):
        """ã‚µã‚¤ã‚¯ãƒ«ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            if not self.loop_cycles:
                return
                
            recent_cycles = self.loop_cycles[-10:]  # æœ€æ–°10ã‚µã‚¤ã‚¯ãƒ«
            
            report = {
                "generated_at": datetime.now().isoformat(),
                "total_cycles": len(self.loop_cycles),
                "recent_cycles_analyzed": len(recent_cycles),
                "summary": {
                    "avg_errors_per_cycle": statistics.mean([c.errors_detected for c in recent_cycles]),
                    "avg_repair_success_rate": statistics.mean([
                        (c.repairs_successful / c.repairs_attempted * 100) if c.repairs_attempted > 0 else 100
                        for c in recent_cycles
                    ]),
                    "avg_validation_score": statistics.mean([c.validation_score for c in recent_cycles]),
                    "system_health_trend": [c.system_health.value for c in recent_cycles[-5:]]
                },
                "performance_trends": {
                    "response_times": list(self.response_times)[-50:] if self.response_times else [],
                    "cpu_usage": list(self.cpu_usage)[-50:] if self.cpu_usage else [],
                    "memory_usage": list(self.memory_usage)[-50:] if self.memory_usage else []
                },
                "recommendations": self._generate_recommendations(recent_cycles)
            }
            
            report_file = self.coordination_path / f"cycle_report_{int(datetime.now().timestamp())}.json"
            async with aiofiles.open(report_file, 'w') as f:
                await f.write(json.dumps(report, indent=2, ensure_ascii=False))
                
            logger.info(f"ğŸ“Š ã‚µã‚¤ã‚¯ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ: {report_file}")
            
        except Exception as e:
            logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _generate_recommendations(self, cycles: List[LoopCycle]) -> List[str]:
        """æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        try:
            if not cycles:
                return recommendations
            
            # ã‚¨ãƒ©ãƒ¼é »åº¦åˆ†æ
            avg_errors = statistics.mean([c.errors_detected for c in cycles])
            if avg_errors > 5:
                recommendations.append("âš ï¸ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿé »åº¦ãŒé«˜ã„ã§ã™ã€‚æ ¹æœ¬åŸå› åˆ†æã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            
            # ä¿®å¾©æˆåŠŸç‡åˆ†æ
            repair_rates = [(c.repairs_successful / c.repairs_attempted * 100) if c.repairs_attempted > 0 else 100 for c in cycles]
            avg_repair_rate = statistics.mean(repair_rates)
            if avg_repair_rate < 70:
                recommendations.append("ğŸ”§ ä¿®å¾©æˆåŠŸç‡ãŒä½ã„ã§ã™ã€‚ä¿®å¾©ãƒ­ã‚¸ãƒƒã‚¯ã®è¦‹ç›´ã—ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            
            # æ¤œè¨¼ã‚¹ã‚³ã‚¢åˆ†æ
            avg_validation = statistics.mean([c.validation_score for c in cycles])
            if avg_validation < 80:
                recommendations.append("âœ… æ¤œè¨¼ã‚¹ã‚³ã‚¢ãŒä½ã„ã§ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ å“è³ªã®æ”¹å–„ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            if len(self.response_times) > 10:
                avg_response = statistics.mean(self.response_times)
                if avg_response > 3.0:
                    recommendations.append("âš¡ ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒé•·ã„ã§ã™ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹åˆ†æ
            health_counts = defaultdict(int)
            for cycle in cycles:
                health_counts[cycle.system_health.value] += 1
            
            if health_counts.get('critical', 0) > 0 or health_counts.get('emergency', 0) > 0:
                recommendations.append("ğŸš¨ ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãŒæ‚ªåŒ–ã—ã¦ã„ã¾ã™ã€‚ç·Šæ€¥ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
            
        except Exception as e:
            logger.error(f"æ¨å¥¨äº‹é …ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            recommendations.append("â“ æ¨å¥¨äº‹é …ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        
        return recommendations
    
    async def _cleanup_and_shutdown(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨çµ‚äº†å‡¦ç†"""
        try:
            logger.info("ğŸ§¹ ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
            
            # æœ€çµ‚çŠ¶æ…‹ä¿å­˜
            await self._save_enhanced_state()
            
            # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            await self._generate_final_report()
            
            logger.info("âœ… ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            logger.error(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _generate_final_report(self):
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            uptime = datetime.now() - self.start_time
            
            final_report = {
                "session_summary": {
                    "start_time": self.start_time.isoformat(),
                    "end_time": datetime.now().isoformat(),
                    "total_uptime_hours": uptime.total_seconds() / 3600,
                    "total_cycles": self.loop_count,
                    "total_errors_fixed": self.total_errors_fixed
                },
                "overall_statistics": {
                    "avg_cycles_per_hour": self.loop_count / (uptime.total_seconds() / 3600) if uptime.total_seconds() > 0 else 0,
                    "avg_fixes_per_cycle": self.total_errors_fixed / self.loop_count if self.loop_count > 0 else 0,
                    "system_availability": self._calculate_availability()
                },
                "performance_summary": {
                    "avg_response_time": statistics.mean(self.response_times) if self.response_times else 0,
                    "avg_cpu_usage": statistics.mean(self.cpu_usage) if self.cpu_usage else 0,
                    "avg_memory_usage": statistics.mean(self.memory_usage) if self.memory_usage else 0
                },
                "recommendations": self._generate_final_recommendations()
            }
            
            final_report_file = self.coordination_path / f"final_session_report_{int(datetime.now().timestamp())}.json"
            async with aiofiles.open(final_report_file, 'w') as f:
                await f.write(json.dumps(final_report, indent=2, ensure_ascii=False))
                
            logger.info(f"ğŸ“‹ æœ€çµ‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ: {final_report_file}")
            
        except Exception as e:
            logger.error(f"æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _calculate_availability(self) -> float:
        """å¯ç”¨æ€§è¨ˆç®—"""
        try:
            if not self.loop_cycles:
                return 100.0
            
            healthy_cycles = sum(1 for cycle in self.loop_cycles 
                               if cycle.system_health in [SystemHealth.OPTIMAL, SystemHealth.GOOD])
            
            return (healthy_cycles / len(self.loop_cycles)) * 100
        except Exception:
            return 0.0
    
    def _generate_final_recommendations(self) -> List[str]:
        """æœ€çµ‚æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        try:
            # å…¨ä½“çš„ãªæ¨å¥¨äº‹é …
            if self.total_errors_fixed > 100:
                recommendations.append("ğŸ”§ å¤šæ•°ã®ã‚¨ãƒ©ãƒ¼ãŒä¿®å¾©ã•ã‚Œã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ã®æ ¹æœ¬çš„ãªè¦‹ç›´ã—ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            
            if self.loop_count > 1000:
                recommendations.append("â±ï¸ é•·æ™‚é–“ã®ç›£è¦–ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚å®šæœŸçš„ãªãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®è¨­å®šã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            
            availability = self._calculate_availability()
            if availability < 95:
                recommendations.append(f"ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ å¯ç”¨æ€§ãŒ {availability:.1f}% ã§ã™ã€‚ç›®æ¨™ã®99%ã‚’ç›®æŒ‡ã—ã¦æ”¹å–„ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            
        except Exception as e:
            logger.error(f"æœ€çµ‚æ¨å¥¨äº‹é …ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        
        return recommendations
    
    def _signal_handler(self, signum, frame):
        """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
        logger.info(f"ğŸ›‘ ã‚·ã‚°ãƒŠãƒ« {signum} ã‚’å—ä¿¡ã€‚ç›£è¦–ã‚’åœæ­¢ã—ã¾ã™ã€‚")
        self.monitoring = False
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        logger.info("ğŸ›‘ ç›£è¦–åœæ­¢è¦æ±‚ã‚’å—ä¿¡")
        self.monitoring = False
    
    def get_status(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®çŠ¶æ³å–å¾—"""
        try:
            return {
                "monitoring": self.monitoring,
                "loop_count": self.loop_count,
                "total_errors_fixed": self.total_errors_fixed,
                "uptime_hours": (datetime.now() - self.start_time).total_seconds() / 3600,
                "current_health": self._assess_system_health().value if hasattr(self, '_assess_system_health') else "unknown",
                "recent_performance": {
                    "avg_response_time": statistics.mean(list(self.response_times)[-10:]) if len(self.response_times) >= 10 else 0,
                    "current_cpu": psutil.cpu_percent(),
                    "current_memory": psutil.virtual_memory().percent
                },
                "last_cycle": self.loop_cycles[-1].__dict__ if self.loop_cycles else None
            }
        except Exception as e:
            logger.error(f"çŠ¶æ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
enhanced_monitor = EnhancedInfiniteLoopMonitor()

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        logger.info("ğŸš€ å¼·åŒ–ã•ã‚ŒãŸç„¡é™ãƒ«ãƒ¼ãƒ—è‡ªå‹•ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
        await enhanced_monitor.start_infinite_loop_monitoring()
    except KeyboardInterrupt:
        logger.info("âŒ¨ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­")
        enhanced_monitor.stop_monitoring()
    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
    finally:
        logger.info("ğŸ ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†")

if __name__ == "__main__":
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler("/media/kensan/LinuxHDD/ITSM-ITmanagementSystem/coordination/enhanced_infinite_loop.log"),
            logging.StreamHandler()
        ]
    )
    
    asyncio.run(main())