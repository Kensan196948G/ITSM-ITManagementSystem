#!/usr/bin/env python3
"""
GitHub Actions ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ©ãƒ¼ç›£è¦–ã¨è‡ªå‹•ä¿®å¾©ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ 
- GitHub Actions APIã‚’ä½¿ç”¨ã—ã¦ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ³ã‚’ç¶™ç¶šç›£è¦–
- ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥ã‹ã‚‰30ç§’ä»¥å†…ã®è‡ªå‹•ä¿®å¾©å®Ÿè¡Œ
- ã‚¨ãƒ©ãƒ¼0ä»¶é”æˆã¾ã§ç¶™ç¶šçš„ãªä¿®å¾©ãƒ«ãƒ¼ãƒ—
"""

import asyncio
import json
import logging
import subprocess
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import re
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

class GitHubActionsMonitor:
    def __init__(self, repo_owner: str = "Kensan196948G", repo_name: str = "ITSM-ITManagementSystem"):
        self.repo_owner = repo_owner
        self.repo_name = repo_name
        self.base_path = Path(__file__).parent
        self.project_root = self.base_path.parent
        
        # ãƒ­ã‚°è¨­å®š
        self.setup_logging()
        
        # ç›£è¦–è¨­å®š
        self.poll_interval = 30  # 30ç§’é–“éš”
        self.max_repair_attempts = 5
        self.error_threshold = 0
        self.consecutive_clean_required = 3
        
        # ç›£è¦–çŠ¶æ…‹
        self.monitoring = False
        self.consecutive_clean_checks = 0
        self.repair_attempt_count = 0
        self.last_workflow_runs = {}
        
        # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³è¾æ›¸
        self.error_patterns = self.load_error_patterns()
        
        # ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        self.repair_actions = self.load_repair_actions()
        
        self.logger.info(f"GitHub Actions Monitor initialized for {repo_owner}/{repo_name}")

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        log_file = self.base_path / "github_actions_monitor.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger("GitHubActionsMonitor")

    def load_error_patterns(self) -> Dict:
        """ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©"""
        return {
            "dependency_errors": {
                "patterns": [
                    r"ModuleNotFoundError: No module named",
                    r"ImportError: cannot import name",
                    r"npm ERR! Cannot resolve dependency",
                    r"pip.*not found",
                    r"Package .* not found",
                    r"requirements.*not satisfied"
                ],
                "severity": "high",
                "auto_fix": True
            },
            "test_failures": {
                "patterns": [
                    r"FAILED.*test_",
                    r"AssertionError",
                    r"Test.*failed",
                    r"ERROR.*pytest",
                    r"jest.*failed"
                ],
                "severity": "medium",
                "auto_fix": True
            },
            "build_errors": {
                "patterns": [
                    r"Build failed",
                    r"compilation error",
                    r"SyntaxError",
                    r"TypeError.*unexpected",
                    r"npm run build.*failed"
                ],
                "severity": "high",
                "auto_fix": True
            },
            "deployment_errors": {
                "patterns": [
                    r"deployment failed",
                    r"server.*not responding",
                    r"connection.*refused",
                    r"timeout.*deploy"
                ],
                "severity": "critical",
                "auto_fix": True
            },
            "config_errors": {
                "patterns": [
                    r"YAML.*syntax error",
                    r"Invalid.*configuration",
                    r"environment variable.*not set",
                    r"secret.*not found"
                ],
                "severity": "high",
                "auto_fix": True
            }
        }

    def load_repair_actions(self) -> Dict:
        """ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å®šç¾©"""
        return {
            "dependency_errors": [
                "pip install -r requirements.txt",
                "npm ci",
                "pip install --upgrade pip",
                "npm install",
                "pip install -e ."
            ],
            "test_failures": [
                "python -m pytest tests/ --tb=short -v",
                "npm test -- --watchAll=false",
                "python -m pytest tests/unit/ -v",
                "python -m pytest tests/api/ -v"
            ],
            "build_errors": [
                "npm run build",
                "python -m py_compile backend/app/*.py",
                "flake8 backend/ --select=E9,F63,F7,F82",
                "npm run lint -- --fix"
            ],
            "deployment_errors": [
                "docker-compose restart",
                "systemctl restart nginx",
                "python backend/run.py &",
                "npm run preview"
            ],
            "config_errors": [
                "cp .env.example .env",
                "python -c \"import yaml; yaml.safe_load(open('.github/workflows/ci.yml'))\"",
                "yamllint .github/workflows/",
                "echo 'DATABASE_URL=sqlite:///./test.db' >> .env"
            ]
        }

    async def check_gh_auth(self) -> bool:
        """GitHub CLIèªè¨¼ç¢ºèª"""
        try:
            result = subprocess.run(["gh", "auth", "status"], 
                                  capture_output=True, text=True, check=False)
            if result.returncode == 0:
                return True
            else:
                self.logger.warning("GitHub CLI not authenticated")
                return False
        except Exception as e:
            self.logger.error(f"GitHub CLI check failed: {e}")
            return False

    async def get_workflow_runs(self) -> List[Dict]:
        """æœ€æ–°ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚’å–å¾—"""
        try:
            cmd = [
                "gh", "api", 
                f"repos/{self.repo_owner}/{self.repo_name}/actions/runs",
                "--jq", ".workflow_runs[:10]"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            runs = json.loads(result.stdout)
            
            self.logger.debug(f"Retrieved {len(runs)} workflow runs")
            return runs
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Failed to get workflow runs: {e}")
            return []
        except Exception as e:
            self.logger.error(f"Error getting workflow runs: {e}")
            return []

    async def get_workflow_logs(self, run_id: str) -> str:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ­ã‚°ã‚’å–å¾—"""
        try:
            cmd = ["gh", "api", f"repos/{self.repo_owner}/{self.repo_name}/actions/runs/{run_id}/logs"]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            return result.stdout
        except Exception as e:
            self.logger.error(f"Failed to get logs for run {run_id}: {e}")
            return ""

    async def analyze_errors(self, logs: str) -> List[Dict]:
        """ãƒ­ã‚°ã‹ã‚‰ã‚¨ãƒ©ãƒ¼ã‚’åˆ†æ"""
        errors = []
        
        for error_type, config in self.error_patterns.items():
            for pattern in config["patterns"]:
                matches = re.findall(pattern, logs, re.IGNORECASE | re.MULTILINE)
                if matches:
                    errors.append({
                        "type": error_type,
                        "pattern": pattern,
                        "matches": matches,
                        "severity": config["severity"],
                        "auto_fix": config["auto_fix"],
                        "count": len(matches)
                    })
        
        return errors

    async def execute_repair_action(self, action: str) -> Tuple[bool, str]:
        """ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        try:
            self.logger.info(f"Executing repair action: {action}")
            
            # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
            if action.startswith("npm"):
                cwd = self.project_root / "frontend"
            elif action.startswith("python") or action.startswith("pip"):
                cwd = self.project_root / "backend"
            else:
                cwd = self.project_root
            
            result = subprocess.run(
                action.split(),
                cwd=cwd,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            
            if result.returncode == 0:
                self.logger.info(f"Repair action successful: {action}")
                return True, result.stdout
            else:
                self.logger.warning(f"Repair action failed: {action} - {result.stderr}")
                return False, result.stderr
                
        except subprocess.TimeoutExpired:
            self.logger.error(f"Repair action timed out: {action}")
            return False, "Timeout"
        except Exception as e:
            self.logger.error(f"Error executing repair action {action}: {e}")
            return False, str(e)

    async def perform_auto_repair(self, errors: List[Dict]) -> bool:
        """è‡ªå‹•ä¿®å¾©å®Ÿè¡Œ"""
        self.logger.info(f"Starting auto-repair for {len(errors)} error types")
        
        repair_success = True
        
        for error in errors:
            if not error["auto_fix"]:
                continue
                
            error_type = error["type"]
            actions = self.repair_actions.get(error_type, [])
            
            self.logger.info(f"Repairing {error_type} with {len(actions)} actions")
            
            for action in actions:
                success, output = await self.execute_repair_action(action)
                if success:
                    self.logger.info(f"Repair successful for {error_type}: {action}")
                    break
                else:
                    self.logger.warning(f"Repair failed for {error_type}: {action}")
                    repair_success = False
        
        return repair_success

    async def trigger_workflow_rerun(self, run_id: str) -> bool:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å†å®Ÿè¡Œ"""
        try:
            cmd = ["gh", "api", 
                   f"repos/{self.repo_owner}/{self.repo_name}/actions/runs/{run_id}/rerun", 
                   "-X", "POST"]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            self.logger.info(f"Triggered rerun for workflow {run_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to trigger workflow rerun {run_id}: {e}")
            return False

    async def save_monitoring_status(self, status: Dict):
        """ç›£è¦–çŠ¶æ³ã‚’ä¿å­˜"""
        status_file = self.base_path / "github_actions_status.json"
        
        status_data = {
            "timestamp": datetime.now().isoformat(),
            "monitoring": self.monitoring,
            "consecutive_clean_checks": self.consecutive_clean_checks,
            "repair_attempts": self.repair_attempt_count,
            "last_check": status.get("timestamp"),
            "total_errors": status.get("total_errors", 0),
            "error_types": status.get("error_types", {}),
            "status": "monitoring" if self.monitoring else "stopped"
        }
        
        with open(status_file, 'w') as f:
            json.dump(status_data, f, indent=2)

    async def monitor_loop(self):
        """ãƒ¡ã‚¤ãƒ³ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        self.logger.info("Starting GitHub Actions monitoring loop")
        self.monitoring = True
        
        while self.monitoring:
            try:
                # GitHub CLIèªè¨¼ç¢ºèª
                if not await self.check_gh_auth():
                    self.logger.error("GitHub CLI not authenticated. Please run: gh auth login")
                    await asyncio.sleep(60)
                    continue
                
                # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚’å–å¾—
                workflow_runs = await self.get_workflow_runs()
                
                if not workflow_runs:
                    self.logger.warning("No workflow runs found")
                    await asyncio.sleep(self.poll_interval)
                    continue
                
                failed_runs = [run for run in workflow_runs if run["conclusion"] == "failure"]
                in_progress_runs = [run for run in workflow_runs if run["status"] == "in_progress"]
                
                self.logger.info(f"Found {len(failed_runs)} failed runs, {len(in_progress_runs)} in progress")
                
                total_errors = 0
                error_types = {}
                
                # å¤±æ•—ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’åˆ†æ
                for run in failed_runs:
                    run_id = run["id"]
                    run_name = run["name"]
                    
                    self.logger.info(f"Analyzing failed run: {run_name} (ID: {run_id})")
                    
                    # ãƒ­ã‚°ã‚’å–å¾—ã—ã¦åˆ†æ
                    logs = await self.get_workflow_logs(str(run_id))
                    if logs:
                        errors = await self.analyze_errors(logs)
                        
                        for error in errors:
                            error_type = error["type"]
                            if error_type not in error_types:
                                error_types[error_type] = 0
                            error_types[error_type] += error["count"]
                            total_errors += error["count"]
                        
                        # è‡ªå‹•ä¿®å¾©å®Ÿè¡Œ
                        if errors and self.repair_attempt_count < self.max_repair_attempts:
                            self.logger.info(f"Starting auto-repair for run {run_id}")
                            self.repair_attempt_count += 1
                            
                            repair_success = await self.perform_auto_repair(errors)
                            
                            if repair_success:
                                # ä¿®å¾©æˆåŠŸæ™‚ã¯ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å†å®Ÿè¡Œ
                                await self.trigger_workflow_rerun(str(run_id))
                                self.logger.info(f"Auto-repair completed, triggered rerun for {run_id}")
                            else:
                                self.logger.error(f"Auto-repair failed for run {run_id}")
                
                # ç›£è¦–çŠ¶æ³ã‚’æ›´æ–°
                status = {
                    "timestamp": datetime.now().isoformat(),
                    "total_errors": total_errors,
                    "error_types": error_types,
                    "failed_runs": len(failed_runs),
                    "in_progress_runs": len(in_progress_runs)
                }
                
                await self.save_monitoring_status(status)
                
                # ã‚¨ãƒ©ãƒ¼0ä»¶ãƒã‚§ãƒƒã‚¯
                if total_errors == 0 and len(failed_runs) == 0:
                    self.consecutive_clean_checks += 1
                    self.logger.info(f"Clean check {self.consecutive_clean_checks}/{self.consecutive_clean_required}")
                    
                    if self.consecutive_clean_checks >= self.consecutive_clean_required:
                        self.logger.info("ğŸ‰ Success! No errors detected for required consecutive checks")
                        # æˆåŠŸçŠ¶æ…‹ã‚’ä¿å­˜
                        status["status"] = "success"
                        status["message"] = "All errors resolved"
                        await self.save_monitoring_status(status)
                        break
                else:
                    self.consecutive_clean_checks = 0
                    self.logger.info(f"Errors detected: {total_errors} total, continuing monitoring")
                
                # æ¬¡ã®ãƒã‚§ãƒƒã‚¯ã¾ã§å¾…æ©Ÿ
                await asyncio.sleep(self.poll_interval)
                
            except KeyboardInterrupt:
                self.logger.info("Monitoring interrupted by user")
                break
            except Exception as e:
                self.logger.error(f"Error in monitoring loop: {e}")
                await asyncio.sleep(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾…æ©Ÿ
        
        self.monitoring = False
        self.logger.info("GitHub Actions monitoring stopped")

    async def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        await self.monitor_loop()

    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.monitoring = False


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Starting GitHub Actions Real-time Error Monitor")
    print("ğŸ“Š Repository: Kensan196948G/ITSM-ITManagementSystem")
    print("â±ï¸  Check interval: 30 seconds")
    print("ğŸ”„ Auto-repair: Enabled")
    print("ğŸ¯ Target: 0 errors with 3 consecutive clean checks")
    print("=" * 60)
    
    monitor = GitHubActionsMonitor()
    
    try:
        await monitor.start_monitoring()
    except KeyboardInterrupt:
        print("\nğŸ›‘ Monitoring stopped by user")
        monitor.stop_monitoring()
    except Exception as e:
        print(f"âŒ Fatal error: {e}")
        monitor.stop_monitoring()


if __name__ == "__main__":
    asyncio.run(main())